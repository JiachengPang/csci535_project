{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported custom modules (utils, models, trainer).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    AutoModel,\n",
    "    RobertaModel,\n",
    "    HubertModel\n",
    ")\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "try:\n",
    "    from utils import get_iemocap_data_loaders, collate_fn_raw, MetricsLogger\n",
    "    from models import TextOnlyModel, AudioOnlyModel\n",
    "    from trainer import Trainer\n",
    "    print(\"Successfully imported custom modules (utils, models, trainer).\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing custom modules: {e}\")\n",
    "    print(\"Please ensure utils.py, models.py, and trainer.py exist and contain the necessary definitions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Configuration ---\n",
      "Device: cuda\n",
      "Number of classes: 5\n",
      "Freeze base model: True\n",
      "Batch Size: 4\n",
      "Learning Rate: 0.003\n",
      "Epochs: 20\n",
      "Patience: 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# --- General Configuration ---\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "\n",
    "# Emotion labels\n",
    "EMOTION_LABELS = ['angry', 'frustrated', 'happy', 'sad', 'neutral']\n",
    "NUM_CLASSES = len(EMOTION_LABELS)\n",
    "\n",
    "# Model checkpoints\n",
    "AUDIO_CHECKPOINT = 'facebook/hubert-base-ls960'\n",
    "TEXT_CHECKPOINT = 'roberta-base'\n",
    "\n",
    "# Data parameters\n",
    "DATA_PATH = './iemocap'\n",
    "PRECOMPUTED_FEATURES = False\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 10\n",
    "LEARNING_RATE = 3e-3\n",
    "N_EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "FREEZE_BASE_MODEL = True\n",
    "\n",
    "print(\"\\n--- Configuration ---\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Freeze base model: {FREEZE_BASE_MODEL}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Epochs: {N_EPOCHS}\")\n",
    "print(f\"Patience: {PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading tokenizer and feature extractor...\n",
      "Tokenizer and feature extractor loaded successfully.\n",
      "\n",
      "Loading data loaders...\n",
      "Distribution after filtering:\n",
      "neutral: 1726\n",
      "frustrated: 2917\n",
      "angry: 1269\n",
      "sad: 1250\n",
      "happy: 2632\n",
      "train, val, test sizes: 7835, 979, 980\n",
      "Data loaders created.\n",
      "Checking a sample batch from train_loader...\n",
      "Sample batch keys: dict_keys(['text_inputs', 'audio_inputs', 'labels'])\n",
      "Text input_ids shape: torch.Size([64, 82])\n",
      "Audio input_values shape: torch.Size([64, 290400])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# --- Load Tokenizer and Processor ---\n",
    "print(\"\\nLoading tokenizer and feature extractor...\")\n",
    "try:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(TEXT_CHECKPOINT)\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_CHECKPOINT)\n",
    "    print(\"Tokenizer and feature extractor loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer/processor: {e}\")\n",
    "    raise RuntimeError(\"Failed to load tokenizer/processor.\") from e\n",
    "\n",
    "# --- Load Data Loaders ---\n",
    "collate_wrapper = lambda b: collate_fn_raw(b, tokenizer, processor)\n",
    "\n",
    "print(\"\\nLoading data loaders...\")\n",
    "try:\n",
    "    train_loader, val_loader, test_loader = get_iemocap_data_loaders(\n",
    "        path=DATA_PATH,\n",
    "        precomputed=PRECOMPUTED_FEATURES,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collate_fn=collate_wrapper,\n",
    "    )\n",
    "    print(\"Data loaders created.\")\n",
    "    # Verify data loaders\n",
    "    print(\"Checking a sample batch from train_loader...\")\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(\"Sample batch keys:\", sample_batch.keys())\n",
    "    if 'text_inputs' in sample_batch:\n",
    "        print(\"Text input_ids shape:\", sample_batch['text_inputs'].get('input_ids', torch.empty(0)).shape)\n",
    "    if 'audio_inputs' in sample_batch:\n",
    "        print(\"Audio input_values shape:\", sample_batch['audio_inputs'].get('input_values', torch.empty(0)).shape)\n",
    "    if 'labels' in sample_batch:\n",
    "        print(\"Labels shape:\", sample_batch['labels'].shape)\n",
    "\n",
    "    # Store loaders for the function\n",
    "    data_loaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader,\n",
    "        'test': test_loader\n",
    "    }\n",
    "\n",
    "except NameError:\n",
    "     print(\"Error: `get_iemocap_data_loaders` or `collate_fn_raw` not found. Check imports.\")\n",
    "     raise RuntimeError(\"Data loading functions not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating data loaders: {e}\")\n",
    "    raise RuntimeError(\"Failed to create data loaders.\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel\n",
    "import copy\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "def run_unimodal_training(model_type, device, config, data_loaders):\n",
    "    \"\"\"\n",
    "    Encapsulates the training and evaluation process for a unimodal model.\n",
    "\n",
    "    Args:\n",
    "        model_type (str): 'text' or 'audio'.\n",
    "        device (str): 'cuda' or 'cpu'.\n",
    "        config (dict): Dictionary containing configuration parameters like\n",
    "                       checkpoints, paths, training settings.\n",
    "        data_loaders (dict): Dictionary containing 'train', 'val', 'test' DataLoaders.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} Starting Training for {model_type.upper()} Model {'='*20}\")\n",
    "\n",
    "    # --- Configuration Specific to this Run ---\n",
    "    if model_type == 'text':\n",
    "        base_checkpoint = config['text_checkpoint']\n",
    "        model_save_path = config['text_model_save_path']\n",
    "        metrics_save_path = config['text_metrics_save_path']\n",
    "        ModelClass = TextOnlyModel\n",
    "    elif model_type == 'audio':\n",
    "        base_checkpoint = config['audio_checkpoint']\n",
    "        model_save_path = config['audio_model_save_path']\n",
    "        metrics_save_path = config['audio_metrics_save_path']\n",
    "        ModelClass = AudioOnlyModel\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'text' or 'audio'\")\n",
    "\n",
    "    num_classes = config['num_classes']\n",
    "    freeze_base = config['freeze_base_model']\n",
    "    lr = config['learning_rate']\n",
    "    n_epochs = config['n_epochs']\n",
    "    patience = config['patience']\n",
    "\n",
    "    # --- Instantiate Logger ---\n",
    "    try:\n",
    "        logger = MetricsLogger(save_path=metrics_save_path)\n",
    "    except NameError:\n",
    "        print(\"Error: MetricsLogger class not found. Check imports from utils.py.\")\n",
    "        return # Stop this run if logger is missing\n",
    "\n",
    "    # --- Load Base Model ---\n",
    "    print(f\"Loading base pre-trained model: {base_checkpoint}...\")\n",
    "    try:\n",
    "        base_model = AutoModel.from_pretrained(base_checkpoint)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading base model {base_checkpoint}: {e}\")\n",
    "        return # Stop this run\n",
    "\n",
    "    # --- Freeze Base Model Parameters ---\n",
    "    if freeze_base:\n",
    "        print(\"Freezing base model parameters.\")\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Base model parameters will be fine-tuned.\")\n",
    "\n",
    "    # --- Instantiate Full Model ---\n",
    "    print(f\"Instantiating {model_type.capitalize()}OnlyModel...\")\n",
    "    hidden_size = base_model.config.hidden_size\n",
    "    try:\n",
    "        # Instantiate the specific model class\n",
    "        if model_type == 'text':\n",
    "             # Pass the actual loaded base_model instance\n",
    "            model = ModelClass(roberta=base_model, num_classes=num_classes, hidden_size=hidden_size)\n",
    "        elif model_type == 'audio':\n",
    "             # Pass the actual loaded base_model instance\n",
    "            model = ModelClass(hubert=base_model, num_classes=num_classes, hidden_size=hidden_size)\n",
    "        print(f\"{model_type.capitalize()}OnlyModel instantiated successfully.\")\n",
    "    except NameError:\n",
    "         print(f\"Error: {ModelClass.__name__} class not found. Check imports from models.py.\")\n",
    "         return # Stop this run if model class is missing\n",
    "    except Exception as e:\n",
    "        print(f\"Error instantiating {ModelClass.__name__}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return # Stop this run\n",
    "\n",
    "    # --- Move Model to Device ---\n",
    "    try:\n",
    "        model.to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error moving model to device {device}: {e}\")\n",
    "        return # Stop this run\n",
    "\n",
    "    # --- Set Up Optimizer ---\n",
    "    params_to_optimize = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.AdamW(params_to_optimize, lr=lr)\n",
    "    print(f\"Optimizer: AdamW with LR={lr}\")\n",
    "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Number of trainable parameters: {num_trainable_params}\")\n",
    "\n",
    "    # --- Instantiate Trainer ---\n",
    "    try:\n",
    "        trainer = Trainer(model, optimizer, device=device)\n",
    "    except NameError:\n",
    "        print(\"Error: Trainer class not found. Check imports from trainer.py.\")\n",
    "        return # Stop this run\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    print(f\"\\nStarting training for {n_epochs} epochs...\")\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        try:\n",
    "            # Train\n",
    "            train_loss, train_acc, train_f1 = trainer.train_one_epoch(data_loaders['train'], epoch)\n",
    "            # Validate\n",
    "            val_loss, val_acc, val_f1 = trainer.evaluate(data_loaders['val'], desc=\"Validate\")\n",
    "\n",
    "            print(f'\\nEpoch {epoch}/{n_epochs}')\n",
    "            print(f'  [Train] Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')\n",
    "            print(f'  [Val]   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}')\n",
    "\n",
    "            # Log metrics\n",
    "            logger.log_train(train_loss, train_acc, train_f1)\n",
    "            logger.log_val(val_loss, val_acc, val_f1)\n",
    "            logger.save()\n",
    "\n",
    "            # Check for improvement and save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = copy.deepcopy(trainer.model.state_dict())\n",
    "                early_stopping_counter = 0\n",
    "                print(f'  -> Validation loss improved to {best_val_loss:.4f}. Saving model state.')\n",
    "                try:\n",
    "                     torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': best_model_state,\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'val_loss': best_val_loss,\n",
    "                        'config': {\n",
    "                             'model_type': model_type,\n",
    "                             'num_classes': num_classes,\n",
    "                             'hidden_size': hidden_size,\n",
    "                             'base_checkpoint': base_checkpoint\n",
    "                        }\n",
    "                    }, model_save_path)\n",
    "                     print(f\"  -> Best model checkpoint saved to '{model_save_path}'\")\n",
    "                except Exception as e_save:\n",
    "                    print(f\"  -> Error saving model checkpoint: {e_save}\")\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f'  -> Validation loss did not improve. Counter: {early_stopping_counter}/{patience}')\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f'\\nEarly stopping triggered after {epoch} epochs.')\n",
    "                break\n",
    "        except Exception as e_epoch:\n",
    "            print(f\"\\nError during epoch {epoch}: {e_epoch}\")\n",
    "            traceback.print_exc()\n",
    "            print(\"Stopping training for this model type due to error.\")\n",
    "            return # Stop this run\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "\n",
    "    # --- Final Evaluation on Test Set ---\n",
    "    print(f\"\\n--- Evaluating Best {model_type.upper()} Model on Test Set ---\")\n",
    "    if best_model_state is None:\n",
    "         print(\"Warning: No best model state was saved (validation loss might not have improved). Evaluating last model state.\")\n",
    "         # Ensure the model used by the trainer is used for evaluation\n",
    "         eval_model = trainer.model # Use the model instance from the trainer\n",
    "         eval_model.eval() # Set to eval mode\n",
    "    elif not os.path.exists(model_save_path):\n",
    "        print(f\"Warning: Best model checkpoint '{model_save_path}' not found, but best state exists in memory. Evaluating model from memory.\")\n",
    "        # Need to load the state into the current model instance\n",
    "        try:\n",
    "            model.load_state_dict(best_model_state)\n",
    "            eval_model = model\n",
    "            eval_model.eval()\n",
    "        except Exception as e_load_mem:\n",
    "             print(f\"Error loading best model state from memory: {e_load_mem}. Cannot evaluate.\")\n",
    "             return\n",
    "    else:\n",
    "        print(f\"Loading best model state from '{model_save_path}'...\")\n",
    "        try:\n",
    "            checkpoint = torch.load(model_save_path, map_location=device)\n",
    "            # Re-initialize architecture - important if script restarted or for consistency\n",
    "            print(\"Re-initializing model architecture for evaluation...\")\n",
    "            eval_config = checkpoint.get('config', {})\n",
    "            eval_num_classes = eval_config.get('num_classes', num_classes)\n",
    "            eval_base_checkpoint = eval_config.get('base_checkpoint', base_checkpoint)\n",
    "            eval_base_model = AutoModel.from_pretrained(eval_base_checkpoint)\n",
    "            eval_hidden_size = eval_config.get('hidden_size', eval_base_model.config.hidden_size)\n",
    "\n",
    "            if model_type == 'text':\n",
    "                 eval_model = TextOnlyModel(roberta=eval_base_model, num_classes=eval_num_classes, hidden_size=eval_hidden_size)\n",
    "            elif model_type == 'audio':\n",
    "                 eval_model = AudioOnlyModel(hubert=eval_base_model, num_classes=eval_num_classes, hidden_size=eval_hidden_size)\n",
    "\n",
    "            eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            eval_model.to(device)\n",
    "            eval_model.eval()\n",
    "            print(\"Best model loaded successfully from file.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Checkpoint file not found at {model_save_path}. Cannot evaluate.\")\n",
    "            return\n",
    "        except Exception as e_load:\n",
    "            print(f\"An error occurred loading the best model: {e_load}\")\n",
    "            traceback.print_exc()\n",
    "            return\n",
    "\n",
    "    # Use the existing Trainer instance structure for evaluation, but with the loaded/best model\n",
    "    # Create a dummy optimizer as Trainer expects one, but it won't be used for eval\n",
    "    eval_optimizer = optim.AdamW(eval_model.parameters(), lr=1e-5)\n",
    "    eval_trainer = Trainer(eval_model, eval_optimizer, device=device)\n",
    "\n",
    "    print(\"\\nRunning evaluation on the test set...\")\n",
    "    try:\n",
    "        test_loss, test_acc, test_f1 = eval_trainer.evaluate(data_loaders['test'], desc=\"Test\")\n",
    "\n",
    "        print(\"\\n--- Test Set Results ---\")\n",
    "        print(f\"  Loss: {test_loss:.4f}\")\n",
    "        print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"  Weighted F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Log test results\n",
    "        logger.log_test(test_loss, test_acc, test_f1)\n",
    "        logger.save()\n",
    "        print(f\"Test metrics logged and saved to {logger.save_path}\")\n",
    "\n",
    "    except Exception as e_eval:\n",
    "        print(f\"An error occurred during final evaluation: {e_eval}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    print(f\"\\n{'='*20} Finished Run for {model_type.upper()} Model {'='*20}\")\n",
    "\n",
    "\n",
    "print(\"Training and evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Starting Training for TEXT Model ====================\n",
      "Loading base pre-trained model: roberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing base model parameters.\n",
      "Instantiating TextOnlyModel...\n",
      "TextOnlyModel initialized (compatible version) with hidden_size=768, num_classes=5\n",
      "TextOnlyModel instantiated successfully.\n",
      "Optimizer: AdamW with LR=0.003\n",
      "Number of trainable parameters: 1185029\n",
      "\n",
      "Starting training for 20 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 123/123 [00:19<00:00,  6.24it/s, loss=1.51]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "  [Train] Loss: 1.5650 | Acc: 0.2850 | F1: 0.2149\n",
      "  [Val]   Loss: 1.5150 | Acc: 0.3524 | F1: 0.2558\n",
      "  -> Validation loss improved to 1.5150. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 123/123 [00:13<00:00,  9.30it/s, loss=1.56]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      "  [Train] Loss: 1.5207 | Acc: 0.3313 | F1: 0.2546\n",
      "  [Val]   Loss: 1.4852 | Acc: 0.3391 | F1: 0.2467\n",
      "  -> Validation loss improved to 1.4852. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 123/123 [00:16<00:00,  7.28it/s, loss=1.43]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "  [Train] Loss: 1.4704 | Acc: 0.3706 | F1: 0.3089\n",
      "  [Val]   Loss: 1.4044 | Acc: 0.3933 | F1: 0.2985\n",
      "  -> Validation loss improved to 1.4044. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 123/123 [00:15<00:00,  8.02it/s, loss=1.42]\n",
      "Validate: 100%|██████████| 16/16 [00:06<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "  [Train] Loss: 1.4407 | Acc: 0.3778 | F1: 0.3242\n",
      "  [Val]   Loss: 1.3731 | Acc: 0.4229 | F1: 0.3703\n",
      "  -> Validation loss improved to 1.3731. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 123/123 [00:12<00:00,  9.92it/s, loss=1.59]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n",
      "  [Train] Loss: 1.4209 | Acc: 0.3871 | F1: 0.3491\n",
      "  [Val]   Loss: 1.3713 | Acc: 0.4208 | F1: 0.3800\n",
      "  -> Validation loss improved to 1.3713. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|██████████| 123/123 [00:15<00:00,  7.88it/s, loss=1.56]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "  [Train] Loss: 1.4089 | Acc: 0.3911 | F1: 0.3623\n",
      "  [Val]   Loss: 1.3216 | Acc: 0.4454 | F1: 0.3774\n",
      "  -> Validation loss improved to 1.3216. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100%|██████████| 123/123 [00:14<00:00,  8.58it/s, loss=1.55]\n",
      "Validate: 100%|██████████| 16/16 [00:04<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n",
      "  [Train] Loss: 1.3995 | Acc: 0.4036 | F1: 0.3799\n",
      "  [Val]   Loss: 1.3547 | Acc: 0.4382 | F1: 0.4232\n",
      "  -> Validation loss did not improve. Counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100%|██████████| 123/123 [00:15<00:00,  7.91it/s, loss=1.31]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "  [Train] Loss: 1.3945 | Acc: 0.3995 | F1: 0.3770\n",
      "  [Val]   Loss: 1.3038 | Acc: 0.4556 | F1: 0.4106\n",
      "  -> Validation loss improved to 1.3038. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 123/123 [00:13<00:00,  9.41it/s, loss=1.3] \n",
      "Validate: 100%|██████████| 16/16 [00:04<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n",
      "  [Train] Loss: 1.3817 | Acc: 0.4031 | F1: 0.3781\n",
      "  [Val]   Loss: 1.3338 | Acc: 0.4454 | F1: 0.4205\n",
      "  -> Validation loss did not improve. Counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 123/123 [00:17<00:00,  6.84it/s, loss=1.44]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "  [Train] Loss: 1.3903 | Acc: 0.3969 | F1: 0.3750\n",
      "  [Val]   Loss: 1.3101 | Acc: 0.4484 | F1: 0.4316\n",
      "  -> Validation loss did not improve. Counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100%|██████████| 123/123 [00:13<00:00,  9.32it/s, loss=1.52]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n",
      "  [Train] Loss: 1.3743 | Acc: 0.4092 | F1: 0.3890\n",
      "  [Val]   Loss: 1.2692 | Acc: 0.4709 | F1: 0.4369\n",
      "  -> Validation loss improved to 1.2692. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100%|██████████| 123/123 [00:12<00:00,  9.91it/s, loss=1.39]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "  [Train] Loss: 1.3733 | Acc: 0.4105 | F1: 0.3848\n",
      "  [Val]   Loss: 1.2874 | Acc: 0.4719 | F1: 0.4311\n",
      "  -> Validation loss did not improve. Counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100%|██████████| 123/123 [00:12<00:00,  9.65it/s, loss=1.3] \n",
      "Validate: 100%|██████████| 16/16 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "  [Train] Loss: 1.3780 | Acc: 0.4040 | F1: 0.3800\n",
      "  [Val]   Loss: 1.2655 | Acc: 0.4668 | F1: 0.4276\n",
      "  -> Validation loss improved to 1.2655. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100%|██████████| 123/123 [00:12<00:00,  9.87it/s, loss=1.18]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "  [Train] Loss: 1.3689 | Acc: 0.4133 | F1: 0.3919\n",
      "  [Val]   Loss: 1.3023 | Acc: 0.4484 | F1: 0.3834\n",
      "  -> Validation loss did not improve. Counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100%|██████████| 123/123 [00:12<00:00,  9.98it/s, loss=1.48]\n",
      "Validate: 100%|██████████| 16/16 [00:06<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "  [Train] Loss: 1.3689 | Acc: 0.4156 | F1: 0.3912\n",
      "  [Val]   Loss: 1.2474 | Acc: 0.4699 | F1: 0.4355\n",
      "  -> Validation loss improved to 1.2474. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100%|██████████| 123/123 [00:12<00:00, 10.08it/s, loss=1.52]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "  [Train] Loss: 1.3577 | Acc: 0.4181 | F1: 0.3976\n",
      "  [Val]   Loss: 1.2932 | Acc: 0.4637 | F1: 0.4330\n",
      "  -> Validation loss did not improve. Counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100%|██████████| 123/123 [00:15<00:00,  8.03it/s, loss=1.43]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n",
      "  [Train] Loss: 1.3645 | Acc: 0.4103 | F1: 0.3882\n",
      "  [Val]   Loss: 1.2738 | Acc: 0.4821 | F1: 0.4380\n",
      "  -> Validation loss did not improve. Counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100%|██████████| 123/123 [00:14<00:00,  8.61it/s, loss=1.13]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20\n",
      "  [Train] Loss: 1.3727 | Acc: 0.4071 | F1: 0.3828\n",
      "  [Val]   Loss: 1.2576 | Acc: 0.4699 | F1: 0.4461\n",
      "  -> Validation loss did not improve. Counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Train]: 100%|██████████| 123/123 [00:15<00:00,  7.76it/s, loss=1.35]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20\n",
      "  [Train] Loss: 1.3555 | Acc: 0.4205 | F1: 0.3987\n",
      "  [Val]   Loss: 1.2167 | Acc: 0.4934 | F1: 0.4459\n",
      "  -> Validation loss improved to 1.2167. Saving model state.\n",
      "  -> Best model checkpoint saved to 'best_text_only_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Train]: 100%|██████████| 123/123 [00:15<00:00,  8.05it/s, loss=1.36]\n",
      "Validate: 100%|██████████| 16/16 [00:03<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/20\n",
      "  [Train] Loss: 1.3481 | Acc: 0.4228 | F1: 0.4025\n",
      "  [Val]   Loss: 1.2956 | Acc: 0.4505 | F1: 0.3932\n",
      "  -> Validation loss did not improve. Counter: 1/5\n",
      "\n",
      "Training finished.\n",
      "\n",
      "--- Evaluating Best TEXT Model on Test Set ---\n",
      "Loading best model state from 'best_text_only_model.pth'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing model architecture for evaluation...\n",
      "TextOnlyModel initialized (compatible version) with hidden_size=768, num_classes=5\n",
      "Best model loaded successfully from file.\n",
      "\n",
      "Running evaluation on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 16/16 [00:06<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Set Results ---\n",
      "  Loss: 1.2648\n",
      "  Accuracy: 0.4867\n",
      "  Weighted F1-Score: 0.4440\n",
      "Test metrics logged and saved to text_only_training_metrics.json\n",
      "\n",
      "==================== Finished Run for TEXT Model ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Define Configuration for the Run ---\n",
    "# Using variables defined in Block 2\n",
    "run_config_text = {\n",
    "    'text_checkpoint': TEXT_CHECKPOINT,\n",
    "    'audio_checkpoint': AUDIO_CHECKPOINT, # Keep both for potential future use in config\n",
    "    'text_model_save_path': 'best_text_only_model.pth',\n",
    "    'text_metrics_save_path': 'text_only_training_metrics.json',\n",
    "    'audio_model_save_path': 'best_audio_only_model.pth', # Keep both for consistency\n",
    "    'audio_metrics_save_path': 'audio_only_training_metrics.json',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'freeze_base_model': FREEZE_BASE_MODEL,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'n_epochs': N_EPOCHS,\n",
    "    'patience': PATIENCE,\n",
    "}\n",
    "\n",
    "# --- Run Training for Text Model ---\n",
    "try:\n",
    "    # Pass necessary variables: model type, device, config dict, data loaders dict\n",
    "    run_unimodal_training(\n",
    "        model_type='text',\n",
    "        device=DEVICE,\n",
    "        config=run_config_text,\n",
    "        data_loaders=data_loaders # data_loaders defined in Block 3\n",
    "    )\n",
    "except NameError as e:\n",
    "    print(f\"Error calling training function for TEXT model: Required variable not defined ({e}). Check previous blocks.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during TEXT model training execution: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared from previous model training.\n",
      "\n",
      "==================== Starting Training for AUDIO Model ====================\n",
      "Loading base pre-trained model: facebook/hubert-base-ls960...\n",
      "Freezing base model parameters.\n",
      "Instantiating AudioOnlyModel...\n",
      "AudioOnlyModel initialized (compatible version) with hidden_size=768, num_classes=5\n",
      "AudioOnlyModel instantiated successfully.\n",
      "Optimizer: AdamW with LR=0.003\n",
      "Number of trainable parameters: 1185029\n",
      "\n",
      "Starting training for 20 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/123 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error during epoch 1: CUDA out of memory. Tried to allocate 3.52 GiB. GPU 0 has a total capacity of 10.00 GiB of which 0 bytes is free. Of the allocated memory 21.57 GiB is allocated by PyTorch, and 54.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Stopping training for this model type due to error.\n",
      "\n",
      "--- All Training Runs Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13444/3535036055.py\", line 114, in run_unimodal_training\n",
      "    train_loss, train_acc, train_f1 = trainer.train_one_epoch(data_loaders['train'], epoch)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/i/Github/csci535_project/trainer.py\", line 35, in train_one_epoch\n",
      "    loss, preds, labels = self.step(batch)\n",
      "                          ^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/i/Github/csci535_project/trainer.py\", line 22, in step\n",
      "    logits = self.model(text_inputs, audio_inputs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/i/Github/csci535_project/models.py\", line 208, in forward\n",
      "    outputs = self.audio_enc(\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py\", line 1302, in forward\n",
      "    extract_features = self.feature_extractor(input_values)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py\", line 216, in forward\n",
      "    hidden_states = conv_layer(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py\", line 121, in forward\n",
      "    hidden_states = self.conv(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 375, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aaaab/anaconda3/envs/535ml/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 370, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.52 GiB. GPU 0 has a total capacity of 10.00 GiB of which 0 bytes is free. Of the allocated memory 21.57 GiB is allocated by PyTorch, and 54.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Free up memory from previous model training\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Run garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "print(\"Memory cleared from previous model training.\")\n",
    "\n",
    "\n",
    "# --- Define Configuration for the Run ---\n",
    "# Re-use most config, paths are handled inside the function based on model_type\n",
    "run_config_audio = {\n",
    "    'text_checkpoint': TEXT_CHECKPOINT,\n",
    "    'audio_checkpoint': AUDIO_CHECKPOINT,\n",
    "    'text_model_save_path': 'best_text_only_model.pth',\n",
    "    'text_metrics_save_path': 'text_only_training_metrics.json',\n",
    "    'audio_model_save_path': 'best_audio_only_model.pth',\n",
    "    'audio_metrics_save_path': 'audio_only_training_metrics.json',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'freeze_base_model': FREEZE_BASE_MODEL,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'n_epochs': N_EPOCHS,\n",
    "    'patience': PATIENCE,\n",
    "}\n",
    "\n",
    "# --- Run Training for Audio Model ---\n",
    "try:\n",
    "     # Pass necessary variables: model type, device, config dict, data loaders dict\n",
    "    run_unimodal_training(\n",
    "        model_type='audio',\n",
    "        device=DEVICE,\n",
    "        config=run_config_audio,\n",
    "        data_loaders=data_loaders # data_loaders defined in Block 3\n",
    "    )\n",
    "except NameError as e:\n",
    "    print(f\"Error calling training function for AUDIO model: Required variable not defined ({e}). Check previous blocks.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during AUDIO model training execution: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n--- All Training Runs Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "535ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
