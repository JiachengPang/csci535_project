{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 20:41:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 48%   58C    P2            115W /  288W |    8260MiB /  10240MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 10\n",
      "Labels: ['neutral', 'happy', 'sad', 'angry', 'frustrated', 'excited', 'fear', 'disgust', 'surprise', 'other']\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Setup and Configuration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_from_disk\n",
    "from tqdm.notebook import tqdm  # Use notebook version of tqdm for better display\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "precomputed_dataset_path = \"./iemocap_precomputed\" # Path where you saved the embeddings\n",
    "model_save_path = \"late_fusion_model.pth\" # Path to save the trained model\n",
    "\n",
    "# Model Hyperparameters (tune these)\n",
    "audio_embedding_dim = 768  # Hubert-base last hidden state dimension\n",
    "text_embedding_dim = 768   # RoBERTa-base last hidden state dimension\n",
    "hidden_dim = 256           # Hidden dimension for the classifier\n",
    "dropout_rate = 0.3         # Dropout rate for regularization\n",
    "learning_rate = 1e-4       # Learning rate for the optimizer\n",
    "batch_size = 32            # Number of samples per batch\n",
    "num_epochs = 15            # Number of training epochs (adjust based on convergence)\n",
    "\n",
    "# Emotion mapping (ensure this matches your preprocessing)\n",
    "emotion_labels = ['neutral', 'happy', 'sad', 'angry', 'frustrated', 'excited', 'fear', 'disgust', 'surprise', 'other']\n",
    "num_classes = len(emotion_labels)\n",
    "label_to_idx = {label: idx for idx, label in enumerate(emotion_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()} # For interpreting results\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Labels: {emotion_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed dataset from ./iemocap_precomputed...\n",
      "Dataset loaded successfully.\n",
      "\n",
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 10039\n",
      "    })\n",
      "})\n",
      "\n",
      "Checking columns in split: 'train'\n",
      "Required columns found.\n",
      "Features in 'train' split: {'file': Value(dtype='string', id=None), 'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None), 'frustrated': Value(dtype='float32', id=None), 'angry': Value(dtype='float32', id=None), 'sad': Value(dtype='float32', id=None), 'disgust': Value(dtype='float32', id=None), 'excited': Value(dtype='float32', id=None), 'fear': Value(dtype='float32', id=None), 'neutral': Value(dtype='float32', id=None), 'surprise': Value(dtype='float32', id=None), 'happy': Value(dtype='float32', id=None), 'EmoAct': Value(dtype='float32', id=None), 'EmoVal': Value(dtype='float32', id=None), 'EmoDom': Value(dtype='float32', id=None), 'gender': Value(dtype='string', id=None), 'transcription': Value(dtype='string', id=None), 'major_emotion': Value(dtype='string', id=None), 'speaking_rate': Value(dtype='float32', id=None), 'pitch_mean': Value(dtype='float32', id=None), 'pitch_std': Value(dtype='float32', id=None), 'rms': Value(dtype='float32', id=None), 'relative_db': Value(dtype='float32', id=None), 'audio_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'text_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'label_id': Value(dtype='int64', id=None)}\n",
      "\n",
      "Sample data item (from 'train' split):\n",
      "{'file': 'Ses01F_impro01_F000.wav', 'audio': {'path': None, 'array': array([-0.0050354 , -0.00497437, -0.0038147 , ..., -0.00265503,\n",
      "       -0.00317383, -0.00418091]), 'sampling_rate': 16000}, 'frustrated': 0.0062500000931322575, 'angry': 0.0062500000931322575, 'sad': 0.0062500000931322575, 'disgust': 0.0062500000931322575, 'excited': 0.0062500000931322575, 'fear': 0.0062500000931322575, 'neutral': 0.949999988079071, 'surprise': 0.0062500000931322575, 'happy': 0.0062500000931322575, 'EmoAct': 2.3333330154418945, 'EmoVal': 2.6666669845581055, 'EmoDom': 2.0, 'gender': 'Female', 'transcription': ' Excuse me.', 'major_emotion': 'neutral', 'speaking_rate': 5.139999866485596, 'pitch_mean': 202.79881286621094, 'pitch_std': 76.12785339355469, 'rms': 0.00788376946002245, 'relative_db': -17.938434600830078, 'audio_embedding': [0.045683152973651886, 0.20088401436805725, 0.06612597405910492, -0.09063911437988281, -0.02926800586283207, -0.08922289311885834, 0.09829737991094589, 1.0580030679702759, 0.013875740580260754, 0.011160682886838913, -0.0810893103480339, 0.19875799119472504, 0.038469161838293076, 0.9251801371574402, -0.06801344454288483, -0.0640806034207344, 0.08015310019254684, 0.30152392387390137, 0.004933026619255543, 0.02779260464012623, -0.42502859234809875, -0.027110164985060692, -0.14114966988563538, -0.2988751232624054, 0.1372036635875702, -0.008449193090200424, -0.12338221073150635, 0.13072194159030914, -0.15498852729797363, -0.17351026833057404, -0.02344273030757904, -0.00649406248703599, -0.12709349393844604, -0.0015035753604024649, -0.10251361131668091, 0.04882941022515297, 0.08957263827323914, 0.19925527274608612, -0.05307844653725624, 0.14156827330589294, 0.01865781843662262, 0.15443694591522217, -0.22021478414535522, 0.37489691376686096, -0.03789294511079788, -0.3054482638835907, 0.05476107820868492, -0.08709333091974258, -0.26910245418548584, -0.0938851609826088, -0.06463722884654999, 0.2751774191856384, 0.07185251265764236, 0.15292640030384064, 0.10955704003572464, 0.05479412153363228, 0.1017107218503952, -0.03568320721387863, -0.0021883000154048204, -0.5272501111030579, 0.062262315303087234, -0.05461639538407326, -0.018818913027644157, 0.01945420540869236, 0.010990523733198643, 0.07865998893976212, -0.08601053059101105, 0.39008739590644836, 0.10418333858251572, 0.11521608382463455, 0.013618766330182552, -0.10330257564783096, -0.056318193674087524, 0.117794930934906, 0.27873894572257996, -0.04655640199780464, 0.19544647634029388, 0.03411073610186577, 0.08079985529184341, -0.11420109122991562, -0.3007308542728424, -0.029916949570178986, -0.10242007672786713, 0.034421879798173904, 0.0045799617655575275, 0.05504107102751732, -0.0013961629010736942, 0.18803341686725616, -0.02642090618610382, 0.07939036935567856, 0.14366421103477478, 0.08101355284452438, -0.0792899876832962, -0.17018762230873108, 0.07164072245359421, -0.12967850267887115, 0.10114746540784836, 0.2053764909505844, 0.07156042754650116, -0.1689445972442627, 0.12681686878204346, 0.06385605037212372, 0.09541996568441391, -0.9746267199516296, -0.09758064150810242, 0.06964518874883652, -0.004692195914685726, -0.17374561727046967, 0.0703655332326889, 0.3710888624191284, 0.1026061624288559, 0.10623335838317871, -0.23791943490505219, -0.05376241356134415, 0.06418128311634064, -0.08345100283622742, 0.08930999785661697, -0.09738247096538544, -0.213681161403656, 0.10735531151294708, 0.06266084313392639, -0.025180624797940254, 0.20096677541732788, -0.09904558956623077, 0.09584688395261765, -0.014668178744614124, -0.12467227876186371, -0.7513942122459412, -0.1802905648946762, -0.06414759159088135, 0.21265414357185364, -0.05261765792965889, -0.060837291181087494, -0.28982973098754883, -0.1709575355052948, -0.19348034262657166, -0.022706065326929092, 0.05811956897377968, -0.18577982485294342, -0.17747481167316437, -0.0342310331761837, 0.5754528641700745, -0.09820477664470673, 0.09248746931552887, -0.13941343128681183, 0.2502712607383728, -0.0281879473477602, -0.000964145758189261, -0.07355699688196182, 0.035490959882736206, 0.18185093998908997, 0.04582182690501213, 0.01947878487408161, 0.1599368453025818, -0.13220103085041046, -0.11874157190322876, -0.11227738857269287, -0.30813315510749817, 0.33604690432548523, 0.0993708148598671, -0.15772101283073425, -0.48811984062194824, 0.1231900006532669, -0.017687376588582993, 0.14375369250774384, 0.17514371871948242, -0.07507257163524628, 0.03105836920440197, 0.03537830337882042, -0.0609590969979763, -0.0731571614742279, 0.16658054292201996, 0.027166292071342468, -0.10204898566007614, 0.04990701749920845, 0.003232615999877453, 0.0730399340391159, 0.29315030574798584, 0.02178575098514557, 0.16606584191322327, 0.010177859105169773, -0.10723724216222763, 0.09293797612190247, 0.08141416311264038, -0.23333466053009033, -0.053871575742959976, 0.1626642793416977, 0.13626888394355774, -0.10557447373867035, 0.07786662131547928, -0.03134126216173172, -0.13070009648799896, -0.19437238574028015, -0.03908328711986542, 0.05287908762693405, 0.06916535645723343, -0.28766176104545593, -0.04045090079307556, 0.06704612076282501, -0.16816844046115875, -0.17945992946624756, 0.09783933311700821, -0.02326362393796444, -0.14454320073127747, -0.04551200196146965, -0.08060578256845474, 0.19636137783527374, 0.09026544541120529, -0.15504860877990723, -0.2321801483631134, 0.10688970983028412, 0.03374437615275383, 0.23959463834762573, -0.1024683490395546, 0.20767490565776825, -0.5912512540817261, 0.06408753991127014, -0.18174098432064056, -0.07495681196451187, -0.2408321499824524, 0.10909854620695114, 0.12301668524742126, 0.2561798095703125, 0.09879729151725769, -0.24288350343704224, 0.013300985097885132, 0.2437451034784317, -0.02069798670709133, 0.11296870559453964, 0.10482219606637955, 0.1070832908153534, 0.025390634313225746, 0.08395977318286896, -0.6513946056365967, 0.14074315130710602, 1.3341563940048218, 0.07361765950918198, 0.2025676965713501, 0.10893166810274124, 0.12339755892753601, -0.06050054728984833, -0.02421259507536888, -0.0048487079329788685, -0.07967645674943924, 0.052215829491615295, -0.02608618140220642, 0.05502970889210701, -0.18991798162460327, -0.08234988152980804, 0.22735080122947693, -0.1080722063779831, 0.08927487581968307, 0.11752873659133911, 0.0004408591485116631, -0.07637534290552139, 0.08782543987035751, 0.07343477010726929, -0.04048847407102585, 0.06923607736825943, 0.08783814311027527, 0.08881896734237671, -0.014229879714548588, -0.07330340147018433, -0.019917428493499756, 0.0761125236749649, -0.2111346572637558, 0.01355558168143034, 0.06308285892009735, 0.0056212954223155975, 0.6341952085494995, 0.0746842548251152, 0.24841035902500153, -0.17758092284202576, -0.2176339030265808, 0.1760086715221405, -0.047217730432748795, -0.2885933518409729, 0.734681248664856, 0.0954933762550354, 0.027309998869895935, -0.08935316652059555, -0.3779694736003876, 0.06879371404647827, 0.1557028740644455, 0.7024863958358765, 0.06609849631786346, 0.14864259958267212, -0.13552023470401764, 0.2871266007423401, 0.0228336863219738, -0.10930477827787399, 0.11604657769203186, 0.04695682227611542, 0.007802559994161129, 0.04074232280254364, -0.11914671957492828, 0.10748817771673203, 0.14311368763446808, -0.0026537165977060795, 0.07286098599433899, 0.006175026763230562, 0.03043465130031109, -0.18581417202949524, -0.008321293629705906, 0.23772776126861572, -0.04850487783551216, 0.04185958206653595, 0.0765107199549675, -0.15425625443458557, 0.19271427392959595, 0.09403707087039948, -0.011613771319389343, -0.0006282980903051794, 0.024834953248500824, -0.16730926930904388, 0.34496867656707764, 0.11956951022148132, 0.004956448916345835, 0.015215182676911354, -0.21040166914463043, 0.16196441650390625, 0.17193260788917542, 0.06829137355089188, -0.04383863881230354, -0.9992437362670898, 0.05709991231560707, 0.04116552695631981, 0.2195758819580078, 0.023465529084205627, -0.0950285866856575, 0.1541743278503418, 0.01985231228172779, 0.20069603621959686, 0.12940528988838196, 0.188070610165596, -0.04874126613140106, -0.016479533165693283, 0.7431136965751648, -0.1796441376209259, -0.037380363792181015, -0.05150037631392479, 0.06368272751569748, 0.08293607831001282, 0.05829770117998123, 0.05698725953698158, 0.14092133939266205, -0.006286191288381815, -0.29116126894950867, 0.17826533317565918, 0.10272043198347092, 0.038585253059864044, 0.018247466534376144, 0.1203465387225151, -0.049127351492643356, -0.046095021069049835, -0.06988806277513504, -0.13925866782665253, -0.14471185207366943, -0.14901623129844666, 0.12758508324623108, 0.15248635411262512, -0.15259288251399994, -0.2164248526096344, -0.3956057131290436, 0.16402293741703033, -0.19225376844406128, 0.08061929792165756, -0.05001799389719963, -0.13871020078659058, -0.04914719983935356, 0.03507314994931221, 0.0763491541147232, 0.10478359460830688, -0.07803897559642792, 0.07773095369338989, -0.0632677972316742, 0.019857628270983696, 0.10083306580781937, 0.04600878059864044, -0.03234861046075821, -0.2905775010585785, 0.1478550285100937, -0.12529058754444122, 0.24924680590629578, -0.032321393489837646, -0.15184763073921204, -0.13835936784744263, 0.2399045079946518, -0.2797863185405731, -0.4958662688732147, 0.10039503872394562, 0.24922126531600952, 0.08965449780225754, -0.01966654509305954, -0.5635781288146973, 0.13309136033058167, -0.1701853722333908, 0.13433153927326202, 0.09482460469007492, -0.49149447679519653, 0.08507252484560013, 0.21745826303958893, 0.19604790210723877, 0.051012322306632996, 0.31337177753448486, -0.1607632040977478, -0.09557060897350311, -0.31917041540145874, 0.010279427282512188, -0.017811061814427376, 0.050345536321401596, 0.04773933067917824, 0.09778089076280594, -0.3552667200565338, -0.05273442342877388, 0.11461181193590164, -0.17949143052101135, -0.018477218225598335, 0.06963575631380081, 0.09738778322935104, 0.08861541748046875, 0.21395039558410645, 0.34270384907722473, 0.15832243859767914, -0.03556785732507706, 0.10094349086284637, 0.18165670335292816, -0.03321966901421547, 0.19309677183628082, 0.04313047602772713, 0.12017358094453812, 0.11551091074943542, -0.1622379720211029, -0.0889657661318779, -0.09578090906143188, -0.3136709928512573, 0.09315066784620285, -0.07062322646379471, -0.03550352528691292, -0.16523303091526031, 0.06650799512863159, -0.5967448949813843, 0.07872898131608963, -0.04717392474412918, 0.05463961884379387, 0.08593738824129105, 0.05796649679541588, 0.019254904240369797, 0.2157825082540512, 0.12948238849639893, -0.013804826885461807, -0.09281608462333679, -0.09376738220453262, -0.4734097421169281, 0.04944080114364624, 0.04158978536725044, -0.21955835819244385, 0.10642831772565842, 0.10094013065099716, -0.2522299885749817, 0.04226144775748253, 0.17319156229496002, 0.04630136862397194, 0.09659792482852936, 0.2936631143093109, -0.0969209223985672, -0.09392660111188889, 0.11162405461072922, 0.12481879442930222, 0.11122213304042816, -0.06722249835729599, 0.08612412959337234, 0.32035526633262634, 0.060362815856933594, 0.04814832657575607, -0.0478610098361969, 0.05495793744921684, 0.12304341048002243, 0.15230140089988708, -0.13440977036952972, -0.20493090152740479, 0.051574017852544785, 1.0023412704467773, -0.13006296753883362, 0.009648777544498444, -0.095944844186306, 0.10528912395238876, -0.5867325067520142, -0.23688946664333344, -0.04756639152765274, 0.10663004964590073, -0.058900173753499985, -0.08780387043952942, -0.1945832371711731, 0.10506277531385422, 0.15800383687019348, 0.08853282779455185, 0.716145932674408, -0.33054524660110474, -0.12641581892967224, -0.09357212483882904, 0.08552846312522888, 0.06306634098291397, 0.1063942015171051, -0.01020718738436699, 0.11479514092206955, -0.04752621054649353, -0.008147525601089, -0.02407585084438324, -0.08318837732076645, -0.15419839322566986, 0.02472311072051525, 0.11653486639261246, -0.029761770740151405, 0.1651809811592102, 0.005992232821881771, 0.184024840593338, 0.29254961013793945, -0.10275943577289581, -0.11819019168615341, -0.7830188274383545, 0.10983917117118835, -0.13001520931720734, -0.7470105290412903, -0.08553394675254822, -0.17680387198925018, 0.0933639332652092, -0.024657249450683594, 0.1173754408955574, -0.09838508814573288, 0.14923903346061707, -0.07936470210552216, -0.12749503552913666, 0.006259335670620203, -0.1263921856880188, -0.04005158320069313, -2.372788190841675, -0.10933484137058258, 0.17889264225959778, -0.10103991627693176, -0.13537144660949707, 0.019375350326299667, 0.07943831384181976, -0.058951541781425476, 0.023897947743535042, 0.03879563882946968, -0.10128717869520187, 0.00046662171371281147, 0.2012486308813095, -0.162839874625206, 0.475856214761734, 0.24277585744857788, -0.002655740361660719, -0.19393670558929443, -0.057890232652425766, -0.3493269681930542, 0.055268749594688416, 0.03714922070503235, 0.008200560696423054, 0.11536171287298203, 0.10073696821928024, -0.1360287219285965, 0.12587212026119232, 0.3092297613620758, 0.1525428593158722, 0.25001585483551025, -0.10180996358394623, -2.358469247817993, -0.009125742129981518, -0.23491798341274261, -0.1925351619720459, -0.010180328041315079, -0.1464836597442627, -0.02750435657799244, 0.3272598683834076, 0.05217403545975685, 0.011083156801760197, 0.05011682212352753, 0.042599085718393326, -0.08873392641544342, 0.05341791734099388, -0.08977973461151123, 0.23634026944637299, 0.009936274960637093, 0.23576891422271729, -0.26215365529060364, -0.06352973729372025, -0.08222661167383194, 0.17152568697929382, 0.08823909610509872, -0.16081644594669342, -0.1764833778142929, -0.3724215030670166, -0.27979257702827454, 0.10882347077131271, 0.07496300339698792, 0.14375212788581848, 0.08127095550298691, 0.10155460983514786, -0.11127890646457672, 0.3327772617340088, -0.11530250310897827, -0.02459549345076084, 0.023526303470134735, 0.18700261414051056, -0.1178588941693306, 0.1550770103931427, -0.09985934942960739, 0.11086603254079819, 0.09561875462532043, 0.054093021899461746, 0.1284576803445816, -0.21615080535411835, 0.3050149381160736, 0.1305389702320099, 0.5593653917312622, 0.15393906831741333, -0.1844639629125595, 0.1413130909204483, 0.061144985258579254, 0.04800393432378769, -0.05347235128283501, -0.06868768483400345, -0.26029863953590393, -0.004973464645445347, -0.2878030240535736, 0.04904070124030113, -0.10216990113258362, -0.1716565191745758, -0.6861727237701416, -0.0008757270989008248, -0.061611026525497437, -0.03402649238705635, 0.11943580955266953, 0.027851147577166557, -0.3870188295841217, 0.20703370869159698, 0.14179173111915588, 0.026421232149004936, -0.08073168247938156, -0.024707119911909103, -0.0649532824754715, 0.01359008252620697, 0.15072572231292725, 0.07823865860700607, 0.06533915549516678, -0.3044438660144806, -0.08180907368659973, 0.21783681213855743, 0.16296297311782837, -0.035651374608278275, 0.22335997223854065, 0.24979273974895477, 0.1387525051832199, 0.1534416675567627, -0.007837277837097645, -0.03682008758187294, -0.010516456328332424, 0.04020347073674202, 0.052819978445768356, -0.021253442391753197, -0.04754495620727539, 0.10560916364192963, -0.13066811859607697, -0.809773862361908, 0.032869428396224976, -0.19149687886238098, 0.18896539509296417, 0.10638286918401718, -0.15122631192207336, 0.11674723029136658, 0.05179499462246895, -0.06697656214237213, 0.12435954064130783, -0.01743808202445507, 0.22493255138397217, -0.28134775161743164, 0.6228632926940918, 0.3196120858192444, -0.21148230135440826, 0.10983016341924667, -0.015436720103025436, -0.3192123770713806, -0.06809528172016144, -0.40317413210868835, -0.1469438225030899, 0.006883540656417608, 0.18777967989444733, -1.0262088775634766, 0.13241346180438995, -0.06461682915687561, -0.016004808247089386, 0.2940811514854431, -0.11738549917936325, -0.08265058696269989, -0.19533613324165344, 0.10098900645971298, -0.1452510952949524, -0.41114377975463867, -0.11500594019889832, -0.02974778413772583, 0.06965851038694382, 0.17183458805084229, 0.05098803713917732, 0.3366357386112213, -0.013341546058654785, 0.05107134208083153, 0.0715741515159607, 0.023015690967440605, -0.0931890681385994, -0.00036419450771063566, 0.05352412536740303, -0.111612968146801, 0.37373897433280945, -0.3816841244697571, -0.03177377209067345, -0.5421323180198669, -0.08435233682394028, 0.021833039820194244, 0.21364006400108337, 0.29306933283805847, -0.19646164774894714, 0.14420051872730255, 0.011302640661597252, -0.10136552155017853, -0.0026192511431872845, -0.18306393921375275, -0.32960376143455505, -0.12149203568696976, -0.13458453118801117, -0.3212513327598572, 0.04305964335799217, -0.17416708171367645, -0.5256377458572388, 0.09142783284187317, -0.5013351440429688, 0.4736747741699219, 0.0280357263982296, -0.001581708318553865, 0.059352874755859375, -0.05482400208711624, 0.19703859090805054, -0.06442614644765854, -0.2580738663673401, 0.16364862024784088, -0.17848029732704163, 0.08132926374673843, 0.11645910888910294, -0.06225119158625603, -0.16868913173675537, -0.17904146015644073, -0.026079649105668068, 0.20158977806568146, -0.06872943043708801, -0.053262241184711456, 0.10330435633659363, -0.1359674036502838, -0.22517803311347961, -0.04916625842452049, -0.3335787355899811, -0.037230152636766434, -0.0029188538901507854, -0.2022593766450882, -0.12058474868535995, -0.0404927134513855, -0.08041712641716003, -0.06323175877332687, 0.09564188122749329], 'text_embedding': [-0.14361950755119324, 0.1069965660572052, -0.015749352052807808, -0.10608608275651932, 0.10848500579595566, -0.031906917691230774, -0.034131187945604324, 0.07010974735021591, 0.0013269323389977217, -0.087117500603199, -0.012580138631165028, 0.02521240897476673, 0.0391315333545208, -0.049620237201452255, 0.04522746801376343, 0.003981208428740501, -0.07270975410938263, -0.005308442749083042, 0.020941011607646942, -0.07954137027263641, -0.11060349643230438, 0.034828972071409225, 0.017374390736222267, 0.12488271296024323, -0.014402994886040688, 0.10280612111091614, 0.1380142718553543, 0.06960704177618027, -0.0002231808175565675, 0.010062413290143013, -0.021067457273602486, -0.06263517588376999, 0.05420009419322014, -0.016452854499220848, 0.015293970704078674, 0.1006271094083786, -0.03295865282416344, 0.005902581848204136, -0.024131514132022858, 0.013075328432023525, -0.0016712835058569908, 0.21400578320026398, 0.026332316920161247, -0.054243266582489014, 0.033806223422288895, 0.010667424649000168, -0.008327512070536613, -0.033302634954452515, -0.03837242349982262, -0.007643989287316799, -0.018831731751561165, 0.10323590785264969, -0.05109792947769165, 0.0741187259554863, -0.18819475173950195, 0.07691404223442078, 0.06985657662153244, 0.050092533230781555, 0.02172066830098629, -0.14030148088932037, -0.0899946540594101, -0.191106915473938, -0.04147478565573692, -0.07844042778015137, 0.09389521181583405, -0.1012115329504013, -0.021505305543541908, -0.02488931454718113, 0.01435766089707613, 0.08898936957120895, 0.03951222077012062, -0.05895572900772095, 0.017056459560990334, 0.0035151110496371984, -0.013342558406293392, -0.04242260754108429, 0.017034878954291344, 0.6100048422813416, -0.06604411453008652, -0.007885422557592392, 0.09082833677530289, -0.07562080025672913, 0.6491041779518127, 0.0653715431690216, -0.02909383922815323, -0.012181608006358147, 0.1370784193277359, 0.013292280025780201, 0.061351560056209564, 0.05911659821867943, -0.008962332271039486, 0.08466913551092148, -0.05362994223833084, 0.06062895804643631, 0.08526851236820221, 0.006287606433033943, -0.1050291508436203, 0.1592818945646286, -0.08639050275087357, -0.10648344457149506, -0.005718578584492207, -0.06725690513849258, 0.05321379005908966, 0.0977352038025856, -0.011180604808032513, 0.0012843121076002717, 0.09681448340415955, -0.048779867589473724, 0.03582664951682091, -0.07043243199586868, -0.02738034725189209, -0.07430224120616913, 0.05334460362792015, -0.016433604061603546, 0.0472337082028389, -0.07539743930101395, 0.01747109927237034, 0.06461776047945023, 0.007876263931393623, -0.005890680942684412, -0.021875176578760147, 0.07733487337827682, 0.10610828548669815, -0.08218048512935638, -0.11671000719070435, -0.10532358288764954, -0.0943717435002327, -0.06495387107133865, 0.025009995326399803, 0.02486802265048027, -0.03300504758954048, -0.1507914960384369, 0.009198999032378197, 0.11091266572475433, 0.04974442347884178, 0.03370774909853935, 0.029016781598329544, -0.027701202780008316, 0.006955258082598448, -0.05715934932231903, 0.0019021120388060808, 0.0020523236598819494, 0.0760556310415268, 0.020245112478733063, 0.14458708465099335, 0.1312875896692276, -0.06174558773636818, -0.04047461971640587, 0.02938210405409336, 0.06868556141853333, 0.10742974281311035, -0.05653902143239975, -0.015448719263076782, -0.013362151570618153, -0.09026883542537689, 0.5211063027381897, 0.12700943648815155, 0.16067703068256378, -0.01268078200519085, 0.021041875705122948, 0.22727105021476746, 0.019663821905851364, 0.028295625001192093, -0.06572883576154709, -0.039347629994153976, 0.0040988619439303875, -0.034559741616249084, -0.023415671661496162, 0.05560639500617981, -0.01869993470609188, 0.09202007204294205, 0.024510351940989494, 0.04307292401790619, -0.04689323157072067, -0.12553422152996063, -0.05578182637691498, 0.10033493489027023, 0.014668996445834637, -0.06082655489444733, 0.0049764723517000675, -0.00399776129052043, 0.09148754924535751, -0.11372807621955872, 0.034118615090847015, -0.034076180309057236, 0.030124470591545105, 0.035906240344047546, 0.019797703251242638, -0.00977295357733965, 0.037016283720731735, 0.06712831556797028, -0.036360591650009155, -0.02446896955370903, -0.08374419808387756, -0.03246847912669182, 0.09781865030527115, -0.0490727573633194, -0.03105073980987072, 0.0380968414247036, -0.10997553914785385, 0.005317007191479206, -0.00924459844827652, 0.16402405500411987, -0.11650440841913223, -0.027756759896874428, -0.02312457747757435, -0.006236930377781391, 0.050481632351875305, 0.000407039828132838, -0.09299860894680023, -0.023551959544420242, 0.026965046301484108, -0.02452434040606022, 0.11542807519435883, 0.10932984203100204, 0.01841980777680874, 0.04395601153373718, 0.16457518935203552, 0.04615303874015808, 0.035244304686784744, 0.062106452882289886, 0.05922723934054375, 0.007506880443543196, 0.026374004781246185, 0.02384171076118946, 0.045940980315208435, 0.04324585571885109, 0.008016484789550304, 0.051009852439165115, 0.011909891851246357, -0.06227443367242813, 0.06112458556890488, 0.034114062786102295, 0.032029230147600174, 0.09983905404806137, -0.14356356859207153, -0.08195376396179199, 0.008071665652096272, -0.06252576410770416, 0.04183867946267128, -0.027790114283561707, 0.13063690066337585, 0.10370911657810211, 0.07828351855278015, -0.009044141508638859, 0.07458695024251938, 0.03242480382323265, 0.04137341305613518, -0.018502729013562202, 0.03324517235159874, -0.023557700216770172, -0.08704884350299835, -0.00020931227481923997, 0.01808619126677513, 0.06121738627552986, -0.02791651152074337, -0.07383260130882263, -0.015779582783579826, -0.05139338597655296, -0.09052083641290665, -0.06431583315134048, -0.01670428179204464, -0.019465778023004532, -0.020313560962677002, -0.12196303904056549, -0.10171111673116684, -0.1389913260936737, -0.032229237258434296, 0.058022256940603256, -0.004801844712346792, -0.012532992288470268, -0.08790554851293564, -0.050731923431158066, -0.022165654227137566, 0.040398914366960526, -0.04109089449048042, 0.007748242933303118, 0.022804848849773407, -0.10053490102291107, 0.032102711498737335, -0.0020467499271035194, -0.07613272219896317, -0.044723715633153915, -0.046665389090776443, 0.019626684486865997, 0.0005763674271292984, -0.11947434395551682, 0.013642998412251472, 0.0057500144466757774, 0.05444476008415222, 0.10254666954278946, -0.0038503457326442003, -0.10974504053592682, 0.02605755813419819, 9.765052527654916e-05, 0.040155861526727676, 0.08507400006055832, -0.033221133053302765, 0.04639078304171562, 0.03384464606642723, -0.06619797646999359, -0.07498858124017715, -0.096407949924469, -0.017211871221661568, -0.018733372911810875, -0.049269068986177444, 0.006842194590717554, -0.029604723677039146, 0.04188991338014603, -0.0032433124724775553, -0.027990277856588364, -0.039397239685058594, -0.11879675835371017, 0.15665121376514435, 0.023439638316631317, 0.026532527059316635, 0.15500089526176453, -0.009639882482588291, 0.0014715079450979829, -0.051011521369218826, -0.021101845428347588, 0.02516140602529049, 0.10228816419839859, -0.02608521096408367, -0.014243473298847675, 0.06725562363862991, -0.016103645786643028, 0.02561909332871437, 0.020941372960805893, 0.31943637132644653, -0.45487019419670105, 0.03463379666209221, 0.06902454048395157, 0.017556829378008842, 0.08101101219654083, -0.010221068747341633, 0.06757093220949173, 0.05597414821386337, 0.10401427000761032, 0.13429400324821472, -0.017344195395708084, 0.021351976320147514, -0.11448028683662415, 0.09493694454431534, 0.04407566413283348, 0.026517177000641823, 0.07981999963521957, -0.08088044822216034, -0.008994015865027905, 0.024511246010661125, -0.05925682559609413, -0.02059822902083397, -0.01000373438000679, -0.10547936707735062, 0.011778192594647408, 0.05008544772863388, 0.002564100082963705, -0.008919810876250267, 0.0021210804115980864, -0.02125670574605465, 0.08449055999517441, -0.07145638018846512, 0.003853574628010392, -0.07254207134246826, 0.03427710384130478, -0.016814732924103737, -0.09157833456993103, 0.12548835575580597, -0.005173675250262022, 0.046582914888858795, 0.10277978330850601, -0.04522975534200668, 0.015289554372429848, 0.024359293282032013, -0.027253665030002594, 0.03049633279442787, 0.04137174040079117, 0.019322236999869347, 0.06602538377046585, 0.20616856217384338, -0.033012863248586655, 0.03848590329289436, -0.09526700526475906, 0.0427410863339901, 0.12354809045791626, -0.10917540639638901, 0.033461760729551315, -0.04126688838005066, 0.034577157348394394, 0.027258550748229027, -0.038480065762996674, -0.06307154893875122, -0.07549961656332016, -0.11359090358018875, 0.06229357793927193, 0.02003868855535984, -0.009942244738340378, -0.11990393698215485, 0.02241530641913414, -0.04528697580099106, 0.020337017253041267, 0.009806911461055279, -0.11912646889686584, 0.04030530899763107, -0.013094830326735973, -0.03038838692009449, -0.009781715460121632, -0.04416700452566147, 0.0017806986579671502, -0.10868881642818451, -0.01581520214676857, 0.019349439069628716, 0.07003889232873917, -0.008662001229822636, 0.06427852064371109, -0.04339515045285225, 0.04147768020629883, -0.02723974920809269, -0.025534646585583687, -0.032551415264606476, -0.12229523807764053, 0.05041142925620079, 0.016868380829691887, -0.024871613830327988, -0.0248919315636158, 0.017377464100718498, 0.0018816681113094091, -0.10713671892881393, -0.08725833147764206, -0.04534991830587387, -0.09208522737026215, 0.0628645047545433, -0.10744979977607727, -0.056423723697662354, -0.036880962550640106, -0.019440822303295135, -0.04960709810256958, 0.030714089050889015, -0.03709212318062782, -0.12141337245702744, -0.03134625032544136, -0.04400208219885826, 0.08330460637807846, 0.007505400571972132, 0.005148523952811956, -0.034592170268297195, 0.0844445750117302, 0.051316700875759125, 0.004638162441551685, 0.07236932218074799, -0.046794772148132324, -0.028219759464263916, -0.09503046423196793, -0.359443336725235, 0.06516511738300323, -0.01399115938693285, -0.0061620376072824, 0.061685122549533844, -0.08817869424819946, 0.028346946462988853, 0.0020338352769613266, -0.0676654502749443, 0.03720922768115997, -0.06558893620967865, 0.04248460754752159, 0.003660375950857997, -0.09379083663225174, -0.01487003080546856, -0.0191632192581892, -0.11674053966999054, 0.0954962819814682, -0.0664501041173935, -0.028424382209777832, -0.14825426042079926, 0.048060499131679535, -0.014942135661840439, 0.03947032243013382, 0.0672064796090126, -0.007286969106644392, -0.02514386922121048, -0.07483470439910889, 0.03469083085656166, 0.06678330898284912, 0.049309682101011276, -0.07664981484413147, -0.042636919766664505, 0.036354947835206985, 0.04179896414279938, 0.1335514932870865, -0.016201134771108627, -0.0006923639448359609, -0.030550766736268997, 0.06611677259206772, 0.08637672662734985, 0.20325975120067596, -0.05615343526005745, 0.2132754921913147, -0.02465386874973774, 0.1758481115102768, 0.04917676001787186, -0.03942319378256798, -0.053021837025880814, -0.06073390319943428, -0.009957830421626568, -0.0461529903113842, 0.02350895293056965, -0.03696379438042641, -0.040518868714571, 0.020317764952778816, 0.012675789184868336, -0.011454669758677483, 0.03976067155599594, 0.1614035815000534, 0.012349992990493774, 0.05727008730173111, 0.0069772726856172085, -0.011713295243680477, -0.010381149128079414, -0.01490350253880024, 0.024683453142642975, -0.02106398530304432, -0.019085751846432686, -0.02924397960305214, -0.03839099034667015, -0.05160827189683914, -0.042067866772413254, 0.0037036940921097994, 0.008933125995099545, 0.13311010599136353, -0.0214400552213192, 0.07783332467079163, 0.003235527314245701, 0.0609346367418766, 0.06421675533056259, 0.03977016359567642, 0.0681842789053917, 0.1406204253435135, -0.021953728049993515, 0.03023572452366352, 0.025798387825489044, -0.061251550912857056, -0.011333486065268517, 0.1286776214838028, -0.05302625894546509, 0.08200681954622269, 0.06614251434803009, 0.008749227039515972, -0.07007182389497757, 0.07993520051240921, -0.062279995530843735, 0.04880614951252937, -0.6495464444160461, -0.025847427546977997, 0.10669413954019547, -0.021444519981741905, -0.017131617292761803, 0.04887889325618744, 0.06168517842888832, -0.029600853100419044, -0.039321381598711014, -0.04457533359527588, 0.1297254115343094, 0.061826515942811966, 0.05357145145535469, -0.050482939928770065, 0.0039255027659237385, 0.04884590208530426, -0.020489061251282692, -0.007941626012325287, 0.06319186091423035, -0.22194862365722656, -0.020210234448313713, -0.06852583587169647, 0.08311812579631805, -0.03798371180891991, 0.05315679311752319, 0.07934892922639847, -0.06057780981063843, 0.017477532848715782, 0.05859125778079033, 0.005246935412287712, 0.05626724287867546, 0.05292025953531265, -0.003956194035708904, 0.04753512516617775, 0.13819390535354614, 0.02106659673154354, 0.020087890326976776, 12.09915828704834, 0.02426004596054554, 0.059583406895399094, -0.044929176568984985, 0.053208280354738235, -0.09458493441343307, 0.0022040780168026686, -0.16429977118968964, -0.0505681186914444, 0.15743201971054077, -0.046684231609106064, -0.04550674930214882, -0.06784326583147049, -0.11066078394651413, 0.06638085097074509, -0.03385227918624878, -0.08620674163103104, -0.03784820809960365, 0.061326783150434494, -0.05015752837061882, -0.040426723659038544, -0.03948298469185829, 0.0030993379186838865, -0.01869187317788601, -0.087763711810112, 0.024678455665707588, 0.07424770295619965, -0.07338043302297592, -0.015167702920734882, 0.059425849467515945, 0.004187397658824921, 0.038144007325172424, 0.038754966109991074, -0.0019772439263761044, 0.07718869298696518, 0.047937795519828796, -0.0068334536626935005, 0.08729138225317001, 0.04989323019981384, 0.09045283496379852, 0.031026236712932587, 0.02126447670161724, 0.1039561852812767, 0.06864812225103378, 0.02091330662369728, 0.04521729052066803, -0.002893476514145732, 0.13273127377033234, 0.035642266273498535, 0.06256525218486786, 0.14920367300510406, -0.06192076951265335, 0.15194572508335114, 0.02521572820842266, 0.018976330757141113, 0.06342834234237671, 0.015933282673358917, -0.014223708771169186, 0.032236624509096146, 0.03515985608100891, -0.0801476314663887, 0.056680917739868164, 0.005279949866235256, 0.056848615407943726, 0.009482083842158318, 0.11499692499637604, 0.09507914632558823, 0.07075364142656326, -0.127147376537323, -0.06324975937604904, -0.020888764411211014, -0.041673798114061356, -0.07615173608064651, 0.037765588611364365, 0.05068519338965416, -0.008968298323452473, -0.06798438727855682, -0.017171211540699005, 6.96698552928865e-05, -0.06058899313211441, -0.044338446110486984, 0.055874068289995193, 0.059442028403282166, -0.04874806106090546, 0.11036110669374466, 0.03815996274352074, 0.035704486072063446, 0.07838032394647598, -0.07921825349330902, -0.08757679164409637, -0.018073689192533493, 0.0002624307235237211, -0.015568372793495655, -0.09216971695423126, 0.009954342618584633, -0.06762804090976715, 0.045973923057317734, -0.16943003237247467, -0.010900777764618397, 0.053116895258426666, -0.15236011147499084, 0.04207862913608551, 0.022449612617492676, 0.07551226764917374, 0.04225795343518257, 0.05119682848453522, -0.007774784229695797, -0.048141565173864365, -0.003299653297290206, -0.01994047313928604, -0.05107830837368965, 0.059234146028757095, 0.0958411768078804, -0.03030797280371189, -0.01121513731777668, 0.05995868146419525, 0.005999727174639702, 0.040651384741067886, 0.03023286908864975, 0.1311865597963333, -0.08661329001188278, -0.014113782905042171, -0.033224817365407944, -0.02235046587884426, -0.06330659240484238, -0.06249980628490448, -0.018662959337234497, 0.06295805424451828, -0.00783470831811428, 0.005842123180627823, -0.02176450565457344, 0.04449324309825897, 0.02323867939412594, -0.09120026975870132, 0.08838585019111633, -0.0834493562579155, -0.07681423425674438, 0.1086319088935852, 0.03122822754085064, 0.0661419928073883, -0.017653634771704674, -0.028780020773410797, -0.059206411242485046, -0.07227317988872528, 0.043637633323669434, 0.07426547259092331, 0.0450579933822155, 0.0761510506272316, 0.10292021185159683, -0.09258852154016495, -0.040198154747486115, 0.09884465485811234, 0.09335146099328995, 0.005083393771201372, 0.02590559422969818, -0.03350836783647537, -0.10622700303792953, 0.0687233954668045, -0.004511137492954731, 0.04294378310441971, 0.06844711303710938, 0.05643950775265694, 0.08199124783277512, 0.0252542681992054, 0.044910017400979996, 0.06712919473648071, 0.015724577009677887, 0.06100994721055031, 0.012250947766005993, -0.035517368465662, 0.0554693266749382, 0.022141607478260994, -0.12412921339273453, -0.08942645788192749, 0.05421092361211777, 0.12394457310438156, 0.06296156346797943, -0.07181734591722488, -0.03527825325727463, -0.05690990388393402], 'label_id': 0}\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Load Precomputed Data\n",
    "print(f\"Loading precomputed dataset from {precomputed_dataset_path}...\")\n",
    "\n",
    "if not os.path.exists(precomputed_dataset_path):\n",
    "    print(f\"ERROR: Dataset directory not found at '{precomputed_dataset_path}'.\")\n",
    "    print(\"Please ensure the path is correct and you have run the preprocessing script.\")\n",
    "    # In a notebook, you might stop execution here or handle it differently\n",
    "    processed_dataset = None\n",
    "else:\n",
    "    try:\n",
    "        processed_dataset = load_from_disk(precomputed_dataset_path)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(\"\\nDataset structure:\")\n",
    "        print(processed_dataset)\n",
    "\n",
    "        # Verify necessary columns exist (important!)\n",
    "        required_columns = ['audio_embedding', 'text_embedding', 'label_id']\n",
    "        # Check in one of the splits, e.g., 'train' if it exists\n",
    "        example_split = next(iter(processed_dataset.keys())) # Get the name of the first split\n",
    "        print(f\"\\nChecking columns in split: '{example_split}'\")\n",
    "        if all(col in processed_dataset[example_split].column_names for col in required_columns):\n",
    "            print(\"Required columns found.\")\n",
    "            print(f\"Features in '{example_split}' split: {processed_dataset[example_split].features}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Missing one or more required columns: {required_columns}\")\n",
    "            print(f\"Available columns: {processed_dataset[example_split].column_names}\")\n",
    "            processed_dataset = None # Invalidate dataset if columns missing\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the dataset: {e}\")\n",
    "        processed_dataset = None\n",
    "\n",
    "# Optional: Display a sample item\n",
    "if processed_dataset and 'train' in processed_dataset:\n",
    "     print(\"\\nSample data item (from 'train' split):\")\n",
    "     print(processed_dataset['train'][0])\n",
    "elif processed_dataset:\n",
    "    example_split = next(iter(processed_dataset.keys()))\n",
    "    print(f\"\\nSample data item (from '{example_split}' split):\")\n",
    "    print(processed_dataset[example_split][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LateFusionModel class defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Define the Late Fusion Model\n",
    "class LateFusionModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, num_classes, hidden_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.audio_dim = audio_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.combined_dim = audio_dim + text_dim # Dimension after concatenation\n",
    "\n",
    "        # Classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Consider LayerNorm for potentially better stability\n",
    "            # nn.LayerNorm(self.combined_dim),\n",
    "            nn.Linear(self.combined_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "            # No Softmax here, nn.CrossEntropyLoss handles it\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embedding, text_embedding):\n",
    "        # Ensure inputs are tensors (DataLoader usually handles this)\n",
    "        # Concatenate along the feature dimension (dim=1)\n",
    "        fused_features = torch.cat((audio_embedding, text_embedding), dim=1)\n",
    "\n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(fused_features)\n",
    "        return logits\n",
    "\n",
    "print(\"LateFusionModel class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated successfully.\n",
      "\n",
      "Model Architecture:\n",
      "LateFusionModel(\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total Trainable Parameters: 396,042\n"
     ]
    }
   ],
   "source": [
    "# Block 4: Instantiate Model and Move to Device\n",
    "\n",
    "# Ensure audio_embedding_dim and text_embedding_dim are correctly set\n",
    "# If they vary, you might need to check the actual embedding dimensions from your dataset\n",
    "if processed_dataset:\n",
    "    try:\n",
    "        # Assuming the embedding dimensions are consistent\n",
    "        # You could double check: len(processed_dataset['train'][0]['audio_embedding'])\n",
    "        model = LateFusionModel(\n",
    "            audio_dim=audio_embedding_dim,\n",
    "            text_dim=text_embedding_dim,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "\n",
    "        print(\"Model instantiated successfully.\")\n",
    "        print(\"\\nModel Architecture:\")\n",
    "        print(model)\n",
    "\n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'\\nTotal Trainable Parameters: {total_params:,}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model instantiation: {e}\")\n",
    "        model = None\n",
    "else:\n",
    "    print(\"Skipping model instantiation because the dataset was not loaded.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No 'validation' or 'dev' split found. Splitting 'train' set...\n",
      "Created 'validation' split from 'train' set.\n",
      "New dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 9035\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 1004\n",
      "    })\n",
      "})\n",
      "Dataset format set to 'torch'.\n",
      "\n",
      "Calculating class weights for the training set...\n",
      "  Class 0 ('neutral'): Count=1556, Weight=0.5807\n",
      "  Class 1 ('happy'): Count=593, Weight=1.5236\n",
      "  Class 2 ('sad'): Count=1121, Weight=0.8060\n",
      "  Class 3 ('angry'): Count=1142, Weight=0.7912\n",
      "  Class 4 ('frustrated'): Count=2632, Weight=0.3433\n",
      "  Class 5 ('excited'): Count=1779, Weight=0.5079\n",
      "  Class 6 ('fear'): Count=93, Weight=9.7151\n",
      "  Class 7 ('disgust'): Count=2, Weight=451.7500\n",
      "  Class 8 ('surprise'): Count=92, Weight=9.8207\n",
      "  Class 9 ('other'): Count=25, Weight=36.1400\n",
      "Class weights calculated and moved to device.\n",
      "\n",
      "Train DataLoader created with 283 batches.\n",
      "Validation DataLoader created with 32 batches.\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Prepare DataLoaders and Handle Imbalance (Optional)\n",
    "\n",
    "# Only run if 'train' exists and 'validation'/'dev' do not\n",
    "if processed_dataset and 'train' in processed_dataset and 'validation' not in processed_dataset and 'dev' not in processed_dataset:\n",
    "    print(\"\\nNo 'validation' or 'dev' split found. Splitting 'train' set...\")\n",
    "    # Split the train set (e.g., 90% train, 10% validation)\n",
    "    # Adjust test_size as needed (e.g., 0.1 for 10%, 0.2 for 20%)\n",
    "    train_val_split = processed_dataset['train'].train_test_split(test_size=0.1, shuffle=True, seed=42) # Use a seed for reproducibility\n",
    "\n",
    "    # Update the dataset dictionary\n",
    "    processed_dataset['train'] = train_val_split['train']\n",
    "    processed_dataset['validation'] = train_val_split['test'] # The 'test' part of the split becomes our validation set\n",
    "\n",
    "    print(\"Created 'validation' split from 'train' set.\")\n",
    "    print(\"New dataset structure:\")\n",
    "    print(processed_dataset)\n",
    "elif processed_dataset and ('validation' in processed_dataset or 'dev' in processed_dataset):\n",
    "    print(\"\\nValidation split already exists.\")\n",
    "elif not processed_dataset:\n",
    "     print(\"\\nCannot create validation split because dataset failed to load.\")\n",
    "\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None # Optional: if you have a test set\n",
    "class_weights = None\n",
    "\n",
    "if processed_dataset and model: # Proceed only if dataset and model are ready\n",
    "    # Set format for PyTorch\n",
    "    try:\n",
    "        processed_dataset.set_format(type='torch', columns=['audio_embedding', 'text_embedding', 'label_id'])\n",
    "        print(\"Dataset format set to 'torch'.\")\n",
    "\n",
    "        # --- Calculate Class Weights (for handling imbalance) ---\n",
    "        if 'train' in processed_dataset:\n",
    "            print(\"\\nCalculating class weights for the training set...\")\n",
    "            label_counts = Counter(processed_dataset['train']['label_id'].numpy())\n",
    "            total_samples = len(processed_dataset['train'])\n",
    "            weights = []\n",
    "            # Ensure weights are calculated in the order of label indices (0 to num_classes-1)\n",
    "            for i in range(num_classes):\n",
    "                count = label_counts.get(i, 0) # Get count, default to 0 if class not present\n",
    "                if count == 0:\n",
    "                     # Assign a default high weight or handle as needed if a class is missing\n",
    "                     print(f\"Warning: Class index {i} ('{idx_to_label.get(i)}') not found in training data. Assigning weight 1.0.\")\n",
    "                     weights.append(1.0)\n",
    "                else:\n",
    "                    # Common formula: weight = total_samples / (num_classes * count)\n",
    "                    weight = total_samples / (num_classes * count)\n",
    "                    weights.append(weight)\n",
    "                    print(f\"  Class {i} ('{idx_to_label.get(i)}'): Count={count}, Weight={weight:.4f}\")\n",
    "\n",
    "            class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "            print(\"Class weights calculated and moved to device.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Skipping class weight calculation: 'train' split not found.\")\n",
    "            class_weights = None # No weights if no train set\n",
    "\n",
    "        # --- Create DataLoaders ---\n",
    "        if 'train' in processed_dataset:\n",
    "            train_dataset = processed_dataset['train']\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "            print(f\"\\nTrain DataLoader created with {len(train_loader)} batches.\")\n",
    "\n",
    "        if 'validation' in processed_dataset: # Common split name\n",
    "            val_dataset = processed_dataset['validation']\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "            print(f\"Validation DataLoader created with {len(val_loader)} batches.\")\n",
    "        elif 'dev' in processed_dataset: # Another common name\n",
    "             val_dataset = processed_dataset['dev']\n",
    "             val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "             print(f\"Development (Validation) DataLoader created with {len(val_loader)} batches.\")\n",
    "\n",
    "        if 'test' in processed_dataset:\n",
    "            test_dataset = processed_dataset['test']\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "            print(f\"Test DataLoader created with {len(test_loader)} batches.\")\n",
    "\n",
    "        # Verify at least train and validation loaders are available for training\n",
    "        if not train_loader or not val_loader:\n",
    "            print(\"\\nWarning: Training requires both train and validation DataLoaders.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError setting dataset format or creating DataLoaders: {e}\")\n",
    "        train_loader, val_loader, test_loader = None, None, None\n",
    "\n",
    "else:\n",
    "    print(\"Skipping DataLoader creation because dataset or model is not ready.\")\n",
    "    \n",
    "\n",
    "\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CrossEntropyLoss with class weights.\n",
      "Loss function and optimizer defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Define Loss Function and Optimizer\n",
    "\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "if model: # Proceed only if model exists\n",
    "    # Use class weights in the loss function if they were calculated\n",
    "    if class_weights is not None:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(\"Using CrossEntropyLoss with class weights.\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(\"Using standard CrossEntropyLoss (no class weights).\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    # You could also add a learning rate scheduler here if desired\n",
    "    # e.g., scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    print(\"Loss function and optimizer defined.\")\n",
    "else:\n",
    "    print(\"Skipping loss/optimizer definition because model is not instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 7: Define Training and Evaluation Functions\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        audio_emb = batch['audio_embedding'].to(device)\n",
    "        text_emb = batch['text_embedding'].to(device)\n",
    "        labels = batch['label_id'].to(device, dtype=torch.long) # Ensure labels are Long\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(audio_emb, text_emb)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        # Optional: Gradient Clipping\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Optional: Step the scheduler if using one like ReduceLROnPlateau based on validation loss\n",
    "    # if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "    #     pass # Step scheduler after evaluation based on validation metric\n",
    "    # elif scheduler:\n",
    "    #      scheduler.step() # For schedulers that step each epoch\n",
    "\n",
    "    return avg_loss, accuracy, f1_macro, f1_weighted\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            audio_emb = batch['audio_embedding'].to(device)\n",
    "            text_emb = batch['text_embedding'].to(device)\n",
    "            labels = batch['label_id'].to(device, dtype=torch.long)\n",
    "\n",
    "            logits = model(audio_emb, text_emb)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"\\nValidation Classification Report:\")\n",
    "    # Use idx_to_label to get names, ensure target_names are in correct order\n",
    "    target_names = [idx_to_label.get(i, f\"Class_{i}\") for i in range(num_classes)]\n",
    "    # Filter labels present in y_true and y_pred to avoid warnings in report\n",
    "    present_labels = sorted(list(set(all_labels) | set(all_preds)))\n",
    "    filtered_target_names = [idx_to_label.get(i, f\"Class_{i}\") for i in present_labels]\n",
    "\n",
    "    try:\n",
    "        print(classification_report(all_labels, all_preds, target_names=filtered_target_names, labels=present_labels, zero_division=0))\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not generate classification report: {e}\")\n",
    "        print(f\"Present labels: {present_labels}\")\n",
    "        print(f\"Target names for report: {filtered_target_names}\")\n",
    "\n",
    "\n",
    "    return avg_loss, accuracy, f1_macro, f1_weighted\n",
    "\n",
    "print(\"Training and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LateFusionModel(\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: True\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe7a70e53d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe7a6bb9eb0>\n",
      "\n",
      "Starting Training...\n",
      "Epochs: 15\n",
      "Batch size: 32\n",
      "Learning rate: 0.0001\n",
      "Device: cuda\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d11921f9efd45f4aa2502b28c1c95f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a7bb5c28584751823c6b7713a08a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.25      0.25      0.25       170\n",
      "       happy       0.12      0.29      0.17        63\n",
      "         sad       0.35      0.68      0.46       129\n",
      "       angry       0.22      0.76      0.34       127\n",
      "  frustrated       0.00      0.00      0.00       285\n",
      "     excited       0.00      0.00      0.00       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.00      0.00      0.00        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.24      1004\n",
      "   macro avg       0.10      0.22      0.14      1004\n",
      "weighted avg       0.12      0.24      0.16      1004\n",
      "\n",
      "\n",
      "Epoch 1/15:\n",
      "  Train Loss: 2.1783 | Train Acc: 0.2069 | Train F1 (Macro): 0.1238 | Train F1 (Weighted): 0.1825\n",
      "  Val Loss:   2.0674 | Val Acc:   0.2430 | Val F1 (Macro): 0.1358 | Val F1 (Weighted): 0.1556\n",
      "  New best validation F1 Macro: 0.1358. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7646544e2c4173bb1407ff160ea6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3964b239d0c49e7b82271623072ef35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.42      0.03      0.05       170\n",
      "       happy       0.13      0.06      0.09        63\n",
      "         sad       0.36      0.67      0.47       129\n",
      "       angry       0.30      0.59      0.40       127\n",
      "  frustrated       0.39      0.29      0.33       285\n",
      "     excited       0.39      0.41      0.40       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.20      0.44      0.28        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.34      1004\n",
      "   macro avg       0.24      0.28      0.22      1004\n",
      "weighted avg       0.35      0.34      0.30      1004\n",
      "\n",
      "\n",
      "Epoch 2/15:\n",
      "  Train Loss: 2.0516 | Train Acc: 0.2874 | Train F1 (Macro): 0.1748 | Train F1 (Weighted): 0.2626\n",
      "  Val Loss:   1.9455 | Val Acc:   0.3406 | Val F1 (Macro): 0.2240 | Val F1 (Weighted): 0.3030\n",
      "  New best validation F1 Macro: 0.2240. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcd6dd8980e4c8d9e919f4ad4eb08dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8de4a79a964fa6b7cf4b3c0ce5c24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.43      0.13      0.20       170\n",
      "       happy       0.14      0.17      0.16        63\n",
      "         sad       0.37      0.69      0.48       129\n",
      "       angry       0.28      0.70      0.40       127\n",
      "  frustrated       0.36      0.12      0.18       285\n",
      "     excited       0.42      0.32      0.36       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.15      0.56      0.24        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      1004\n",
      "   macro avg       0.24      0.30      0.22      1004\n",
      "weighted avg       0.35      0.32      0.28      1004\n",
      "\n",
      "\n",
      "Epoch 3/15:\n",
      "  Train Loss: 1.9775 | Train Acc: 0.3061 | Train F1 (Macro): 0.1889 | Train F1 (Weighted): 0.2831\n",
      "  Val Loss:   1.8784 | Val Acc:   0.3177 | Val F1 (Macro): 0.2244 | Val F1 (Weighted): 0.2837\n",
      "  New best validation F1 Macro: 0.2244. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412cdd9f1d3f4033896f377b3ab12061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652b7dc58b054ad29a4aa00319d229d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.34      0.15      0.20       170\n",
      "       happy       0.17      0.06      0.09        63\n",
      "         sad       0.42      0.60      0.49       129\n",
      "       angry       0.30      0.70      0.42       127\n",
      "  frustrated       0.37      0.23      0.28       285\n",
      "     excited       0.41      0.40      0.40       197\n",
      "        fear       0.17      0.07      0.10        14\n",
      "    surprise       0.21      0.56      0.30        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35      1004\n",
      "   macro avg       0.26      0.31      0.26      1004\n",
      "weighted avg       0.35      0.35      0.32      1004\n",
      "\n",
      "\n",
      "Epoch 4/15:\n",
      "  Train Loss: 1.9382 | Train Acc: 0.3184 | Train F1 (Macro): 0.2038 | Train F1 (Weighted): 0.2979\n",
      "  Val Loss:   1.8532 | Val Acc:   0.3486 | Val F1 (Macro): 0.2552 | Val F1 (Weighted): 0.3226\n",
      "  New best validation F1 Macro: 0.2552. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8bde421a7148d7ae9c799d3fe4b762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e368b34074594a9aafbb5ce5b30dde96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.47      0.11      0.17       170\n",
      "       happy       0.12      0.21      0.15        63\n",
      "         sad       0.40      0.72      0.51       129\n",
      "       angry       0.30      0.72      0.42       127\n",
      "  frustrated       0.35      0.16      0.22       285\n",
      "     excited       0.43      0.24      0.31       197\n",
      "        fear       0.07      0.21      0.10        14\n",
      "    surprise       0.21      0.39      0.27        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      1004\n",
      "   macro avg       0.26      0.31      0.24      1004\n",
      "weighted avg       0.36      0.32      0.29      1004\n",
      "\n",
      "\n",
      "Epoch 5/15:\n",
      "  Train Loss: 1.8915 | Train Acc: 0.3339 | Train F1 (Macro): 0.2168 | Train F1 (Weighted): 0.3182\n",
      "  Val Loss:   1.8067 | Val Acc:   0.3167 | Val F1 (Macro): 0.2404 | Val F1 (Weighted): 0.2873\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2582f648237845ab8b3f31bda13851fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954f67aec4c843a9afe08ae82f3bbc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.42      0.19      0.27       170\n",
      "       happy       0.14      0.25      0.18        63\n",
      "         sad       0.41      0.72      0.52       129\n",
      "       angry       0.38      0.65      0.48       127\n",
      "  frustrated       0.47      0.26      0.34       285\n",
      "     excited       0.45      0.25      0.32       197\n",
      "        fear       0.09      0.14      0.11        14\n",
      "    surprise       0.17      0.67      0.27        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36      1004\n",
      "   macro avg       0.28      0.35      0.28      1004\n",
      "weighted avg       0.41      0.36      0.35      1004\n",
      "\n",
      "\n",
      "Epoch 6/15:\n",
      "  Train Loss: 1.8605 | Train Acc: 0.3416 | Train F1 (Macro): 0.2239 | Train F1 (Weighted): 0.3299\n",
      "  Val Loss:   1.7612 | Val Acc:   0.3616 | Val F1 (Macro): 0.2756 | Val F1 (Weighted): 0.3489\n",
      "  New best validation F1 Macro: 0.2756. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e677fba17d114b3687417d87d672d03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1fd2addf3e41688b75ff3b84b1793d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.38      0.40      0.39       170\n",
      "       happy       0.18      0.16      0.17        63\n",
      "         sad       0.46      0.63      0.53       129\n",
      "       angry       0.33      0.70      0.45       127\n",
      "  frustrated       0.45      0.16      0.24       285\n",
      "     excited       0.45      0.34      0.39       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.18      0.67      0.29        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.37      1004\n",
      "   macro avg       0.27      0.34      0.27      1004\n",
      "weighted avg       0.40      0.37      0.35      1004\n",
      "\n",
      "\n",
      "Epoch 7/15:\n",
      "  Train Loss: 1.8324 | Train Acc: 0.3484 | Train F1 (Macro): 0.2344 | Train F1 (Weighted): 0.3403\n",
      "  Val Loss:   1.7540 | Val Acc:   0.3725 | Val F1 (Macro): 0.2731 | Val F1 (Weighted): 0.3522\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b969bda89b2c4bf39bc7be455f7c5f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc03320d2e60495b83e8154b6e634423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.48      0.31      0.37       170\n",
      "       happy       0.16      0.29      0.20        63\n",
      "         sad       0.43      0.73      0.54       129\n",
      "       angry       0.39      0.62      0.48       127\n",
      "  frustrated       0.52      0.24      0.32       285\n",
      "     excited       0.45      0.35      0.39       197\n",
      "        fear       0.12      0.14      0.13        14\n",
      "    surprise       0.19      0.67      0.29        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.39      1004\n",
      "   macro avg       0.30      0.37      0.30      1004\n",
      "weighted avg       0.44      0.39      0.38      1004\n",
      "\n",
      "\n",
      "Epoch 8/15:\n",
      "  Train Loss: 1.7960 | Train Acc: 0.3668 | Train F1 (Macro): 0.2488 | Train F1 (Weighted): 0.3595\n",
      "  Val Loss:   1.7213 | Val Acc:   0.3904 | Val F1 (Macro): 0.3041 | Val F1 (Weighted): 0.3818\n",
      "  New best validation F1 Macro: 0.3041. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb16319fe1784da6a5b5441d22d969bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf57db7e31046c38f8398f6288db9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.41      0.43      0.42       170\n",
      "       happy       0.19      0.16      0.17        63\n",
      "         sad       0.43      0.72      0.54       129\n",
      "       angry       0.40      0.58      0.47       127\n",
      "  frustrated       0.51      0.21      0.30       285\n",
      "     excited       0.45      0.38      0.41       197\n",
      "        fear       0.08      0.29      0.12        14\n",
      "    surprise       0.24      0.56      0.34        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40      1004\n",
      "   macro avg       0.30      0.37      0.31      1004\n",
      "weighted avg       0.43      0.40      0.39      1004\n",
      "\n",
      "\n",
      "Epoch 9/15:\n",
      "  Train Loss: 1.7694 | Train Acc: 0.3641 | Train F1 (Macro): 0.2475 | Train F1 (Weighted): 0.3572\n",
      "  Val Loss:   1.7149 | Val Acc:   0.3974 | Val F1 (Macro): 0.3093 | Val F1 (Weighted): 0.3858\n",
      "  New best validation F1 Macro: 0.3093. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a2143d8611492099c7502bebb2f82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ce0e7eac2849b6813c14f93ba21bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.49      0.23      0.31       170\n",
      "       happy       0.17      0.27      0.20        63\n",
      "         sad       0.45      0.70      0.55       129\n",
      "       angry       0.35      0.72      0.47       127\n",
      "  frustrated       0.45      0.21      0.29       285\n",
      "     excited       0.47      0.35      0.40       197\n",
      "        fear       0.13      0.14      0.14        14\n",
      "    surprise       0.18      0.67      0.29        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38      1004\n",
      "   macro avg       0.30      0.36      0.29      1004\n",
      "weighted avg       0.42      0.38      0.36      1004\n",
      "\n",
      "\n",
      "Epoch 10/15:\n",
      "  Train Loss: 1.7515 | Train Acc: 0.3744 | Train F1 (Macro): 0.2523 | Train F1 (Weighted): 0.3676\n",
      "  Val Loss:   1.6863 | Val Acc:   0.3785 | Val F1 (Macro): 0.2943 | Val F1 (Weighted): 0.3630\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abef13dbb4454277a7b9d3c50566c831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e30aee6a11e44969159d6907b7ffcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.43      0.44      0.43       170\n",
      "       happy       0.19      0.21      0.20        63\n",
      "         sad       0.46      0.65      0.54       129\n",
      "       angry       0.39      0.66      0.49       127\n",
      "  frustrated       0.50      0.24      0.32       285\n",
      "     excited       0.49      0.37      0.42       197\n",
      "        fear       0.09      0.21      0.13        14\n",
      "    surprise       0.23      0.67      0.34        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41      1004\n",
      "   macro avg       0.31      0.38      0.32      1004\n",
      "weighted avg       0.44      0.41      0.40      1004\n",
      "\n",
      "\n",
      "Epoch 11/15:\n",
      "  Train Loss: 1.7243 | Train Acc: 0.3832 | Train F1 (Macro): 0.2613 | Train F1 (Weighted): 0.3777\n",
      "  Val Loss:   1.6738 | Val Acc:   0.4074 | Val F1 (Macro): 0.3192 | Val F1 (Weighted): 0.3978\n",
      "  New best validation F1 Macro: 0.3192. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54606c7ff92043b3ac206cca451ee36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b6927dbc4c418fa3af00fabc29f741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.48      0.34      0.40       170\n",
      "       happy       0.18      0.33      0.23        63\n",
      "         sad       0.44      0.73      0.55       129\n",
      "       angry       0.40      0.57      0.47       127\n",
      "  frustrated       0.50      0.24      0.32       285\n",
      "     excited       0.46      0.29      0.36       197\n",
      "        fear       0.07      0.07      0.07        14\n",
      "    surprise       0.13      0.67      0.22        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38      1004\n",
      "   macro avg       0.29      0.36      0.29      1004\n",
      "weighted avg       0.43      0.38      0.38      1004\n",
      "\n",
      "\n",
      "Epoch 12/15:\n",
      "  Train Loss: 1.6987 | Train Acc: 0.3904 | Train F1 (Macro): 0.2662 | Train F1 (Weighted): 0.3843\n",
      "  Val Loss:   1.6434 | Val Acc:   0.3825 | Val F1 (Macro): 0.2905 | Val F1 (Weighted): 0.3780\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be5e8cca43846dba52fdfb3c48cc703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fc04e3b01042fa8f17787e9e4bd233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.45      0.49      0.47       170\n",
      "       happy       0.20      0.27      0.23        63\n",
      "         sad       0.47      0.61      0.53       129\n",
      "       angry       0.36      0.68      0.47       127\n",
      "  frustrated       0.52      0.22      0.31       285\n",
      "     excited       0.54      0.31      0.39       197\n",
      "        fear       0.07      0.21      0.10        14\n",
      "    surprise       0.23      0.61      0.33        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40      1004\n",
      "   macro avg       0.32      0.38      0.32      1004\n",
      "weighted avg       0.45      0.40      0.39      1004\n",
      "\n",
      "\n",
      "Epoch 13/15:\n",
      "  Train Loss: 1.6825 | Train Acc: 0.3969 | Train F1 (Macro): 0.2741 | Train F1 (Weighted): 0.3921\n",
      "  Val Loss:   1.6360 | Val Acc:   0.4024 | Val F1 (Macro): 0.3160 | Val F1 (Weighted): 0.3950\n",
      "  Validation F1 Macro did not improve. (2/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114e9c9b9b2e4a289573de377ff0a476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6917a7e6752a4441831ea9a3fce644a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.46      0.38      0.41       170\n",
      "       happy       0.24      0.29      0.26        63\n",
      "         sad       0.47      0.62      0.54       129\n",
      "       angry       0.38      0.65      0.48       127\n",
      "  frustrated       0.48      0.30      0.37       285\n",
      "     excited       0.52      0.34      0.41       197\n",
      "        fear       0.08      0.21      0.12        14\n",
      "    surprise       0.21      0.67      0.32        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41      1004\n",
      "   macro avg       0.31      0.38      0.32      1004\n",
      "weighted avg       0.44      0.41      0.41      1004\n",
      "\n",
      "\n",
      "Epoch 14/15:\n",
      "  Train Loss: 1.6584 | Train Acc: 0.4003 | Train F1 (Macro): 0.2769 | Train F1 (Weighted): 0.3955\n",
      "  Val Loss:   1.6233 | Val Acc:   0.4094 | Val F1 (Macro): 0.3221 | Val F1 (Weighted): 0.4076\n",
      "  New best validation F1 Macro: 0.3221. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16370c6ad7704dd09764c4245580665d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976618cbcf94446e9f13e936836d493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.47      0.46      0.47       170\n",
      "       happy       0.21      0.35      0.27        63\n",
      "         sad       0.45      0.70      0.55       129\n",
      "       angry       0.35      0.71      0.47       127\n",
      "  frustrated       0.50      0.17      0.26       285\n",
      "     excited       0.51      0.21      0.29       197\n",
      "        fear       0.05      0.14      0.07        14\n",
      "    surprise       0.21      0.67      0.32        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38      1004\n",
      "   macro avg       0.31      0.38      0.30      1004\n",
      "weighted avg       0.44      0.38      0.36      1004\n",
      "\n",
      "\n",
      "Epoch 15/15:\n",
      "  Train Loss: 1.6367 | Train Acc: 0.4101 | Train F1 (Macro): 0.2819 | Train F1 (Weighted): 0.4059\n",
      "  Val Loss:   1.6250 | Val Acc:   0.3825 | Val F1 (Macro): 0.2988 | Val F1 (Weighted): 0.3620\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n",
      "\n",
      "Training finished.\n",
      "Loading model state from epoch with best validation F1 Macro: 0.3221\n"
     ]
    }
   ],
   "source": [
    "# Block 8: Training Loop\n",
    "\n",
    "# --- Early Stopping Parameters ---\n",
    "early_stopping_patience = 3  # Stop after N epochs with no improvement in validation F1 macro\n",
    "best_val_f1_macro = -1.0     # Initialize best validation F1 score\n",
    "epochs_no_improve = 0       # Counter for epochs without improvement\n",
    "best_model_state = None     # To store the state dict of the best model\n",
    "\n",
    "print(model)\n",
    "print(criterion)\n",
    "print(optimizer)\n",
    "print(train_loader)\n",
    "print(val_loader)\n",
    "\n",
    "# --- Check if we can proceed ---\n",
    "if model and criterion and optimizer and train_loader and val_loader:\n",
    "    print(\"\\nStarting Training...\")\n",
    "    print(f\"Epochs: {num_epochs}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training ---\n",
    "        train_loss, train_acc, train_f1_macro, train_f1_weighted = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device #, scheduler # Pass scheduler if using one\n",
    "        )\n",
    "\n",
    "        # --- Evaluation ---\n",
    "        val_loss, val_acc, val_f1_macro, val_f1_weighted = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1 (Macro): {train_f1_macro:.4f} | Train F1 (Weighted): {train_f1_weighted:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val F1 (Macro): {val_f1_macro:.4f} | Val F1 (Weighted): {val_f1_weighted:.4f}\")\n",
    "\n",
    "        # --- Optional: Learning Rate Scheduler Step (if based on validation metric) ---\n",
    "        # if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        #     scheduler.step(val_loss) # or scheduler.step(val_f1_macro) if monitoring F1\n",
    "        #     current_lr = optimizer.param_groups[0]['lr']\n",
    "        #     print(f\"  Current LR: {current_lr:.6f}\")\n",
    "\n",
    "        # --- Early Stopping Check ---\n",
    "        if val_f1_macro > best_val_f1_macro:\n",
    "            best_val_f1_macro = val_f1_macro\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model state\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  New best validation F1 Macro: {best_val_f1_macro:.4f}. Saving model state.\")\n",
    "            # Optionally save immediately: torch.save(model.state_dict(), model_save_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Validation F1 Macro did not improve. ({epochs_no_improve}/{early_stopping_patience})\")\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs.\")\n",
    "            break # Exit the training loop\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "\n",
    "    # --- Load Best Model State ---\n",
    "    if best_model_state:\n",
    "        print(f\"Loading model state from epoch with best validation F1 Macro: {best_val_f1_macro:.4f}\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"No best model state was saved (perhaps training stopped early or validation metric never improved).\")\n",
    "\n",
    "else:\n",
    "    # Check which components are missing for training   \n",
    "    print(\"\\nSkipping training loop due to missing model, data, loss function, or optimizer.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "535ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
