{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 23:05:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 45%   62C    P2            115W /  288W |    5782MiB /  10240MiB |     20%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 10\n",
      "Fusion strategy: Logit Averaging (within single model)\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Setup and Configuration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import copy # For saving best model state\n",
    "\n",
    "# --- Configuration ---\n",
    "precomputed_dataset_path = \"./iemocap_precomputed\" # Path where you saved the embeddings\n",
    "# <<< CHANGE: Only one model save path needed >>>\n",
    "model_save_path = \"combined_decision_avg_model.pth\"\n",
    "\n",
    "# Model Hyperparameters (can still have separate hidden dims if desired)\n",
    "audio_embedding_dim = 768\n",
    "text_embedding_dim = 768\n",
    "audio_hidden_dim = 128 # Hidden dim for the audio pathway inside the combined model\n",
    "text_hidden_dim = 128  # Hidden dim for the text pathway inside the combined model\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Training Hyperparameters\n",
    "learning_rate = 1e-4 # <<< CHANGE: One LR for the combined model >>>\n",
    "batch_size = 32\n",
    "num_epochs = 15 # Number of training epochs for the combined model\n",
    "\n",
    "# Emotion mapping (ensure this matches your preprocessing)\n",
    "emotion_labels = ['neutral', 'happy', 'sad', 'angry', 'frustrated', 'excited', 'fear', 'disgust', 'surprise', 'other']\n",
    "num_classes = len(emotion_labels)\n",
    "label_to_idx = {label: idx for idx, label in enumerate(emotion_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Fusion strategy: Logit Averaging (within single model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed dataset from ./iemocap_precomputed...\n",
      "Dataset loaded successfully.\n",
      "\n",
      "Initial dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 10039\n",
      "    })\n",
      "})\n",
      "\n",
      "No 'validation' or 'dev' split found. Attempting to split 'train' set...\n",
      "Created 'validation' split from 'train' set.\n",
      "Updated dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 9035\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['file', 'audio', 'frustrated', 'angry', 'sad', 'disgust', 'excited', 'fear', 'neutral', 'surprise', 'happy', 'EmoAct', 'EmoVal', 'EmoDom', 'gender', 'transcription', 'major_emotion', 'speaking_rate', 'pitch_mean', 'pitch_std', 'rms', 'relative_db', 'audio_embedding', 'text_embedding', 'label_id'],\n",
      "        num_rows: 1004\n",
      "    })\n",
      "})\n",
      "Required columns found.\n",
      "\n",
      "Dataset format set to 'torch'.\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Load Precomputed Data & Create Splits (If Necessary)\n",
    "\n",
    "processed_dataset = None\n",
    "print(f\"Loading precomputed dataset from {precomputed_dataset_path}...\")\n",
    "\n",
    "if not os.path.exists(precomputed_dataset_path):\n",
    "    print(f\"ERROR: Dataset directory not found at '{precomputed_dataset_path}'.\")\n",
    "else:\n",
    "    try:\n",
    "        processed_dataset = load_from_disk(precomputed_dataset_path)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        print(\"\\nInitial dataset structure:\")\n",
    "        print(processed_dataset)\n",
    "\n",
    "        # --- Ensure Validation Split Exists ---\n",
    "        validation_split_name = 'validation' # Default name\n",
    "        if 'validation' not in processed_dataset and 'dev' not in processed_dataset:\n",
    "            print(\"\\nNo 'validation' or 'dev' split found. Attempting to split 'train' set...\")\n",
    "            if 'train' in processed_dataset:\n",
    "                 # Split the train set (e.g., 90% train, 10% validation)\n",
    "                 train_val_split = processed_dataset['train'].train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "                 processed_dataset['train'] = train_val_split['train']\n",
    "                 processed_dataset['validation'] = train_val_split['test']\n",
    "                 print(\"Created 'validation' split from 'train' set.\")\n",
    "                 print(\"Updated dataset structure:\")\n",
    "                 print(processed_dataset)\n",
    "            else:\n",
    "                 print(\"ERROR: Cannot create validation split because 'train' split is missing.\")\n",
    "                 processed_dataset = None # Invalidate if no train set to split from\n",
    "        elif 'dev' in processed_dataset:\n",
    "             validation_split_name = 'dev' # Use 'dev' if it exists\n",
    "             print(\"\\nValidation split ('dev') found.\")\n",
    "        else:\n",
    "            print(\"\\nValidation split ('validation') found.\")\n",
    "\n",
    "        # --- Verify Columns ---\n",
    "        if processed_dataset:\n",
    "            required_columns = ['audio_embedding', 'text_embedding', 'label_id']\n",
    "            example_split = next(iter(processed_dataset.keys()))\n",
    "            if all(col in processed_dataset[example_split].column_names for col in required_columns):\n",
    "                print(\"Required columns found.\")\n",
    "            else:\n",
    "                print(f\"ERROR: Missing one or more required columns: {required_columns}\")\n",
    "                print(f\"Available columns: {processed_dataset[example_split].column_names}\")\n",
    "                processed_dataset = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading or processing the dataset: {e}\")\n",
    "        processed_dataset = None\n",
    "\n",
    "# --- Set Format for PyTorch ---\n",
    "if processed_dataset:\n",
    "    try:\n",
    "        processed_dataset.set_format(type='torch', columns=['audio_embedding', 'text_embedding', 'label_id'])\n",
    "        print(\"\\nDataset format set to 'torch'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting dataset format: {e}\")\n",
    "        processed_dataset = None\n",
    "else:\n",
    "     # Ensure validation_split_name is defined even if dataset loading fails, to avoid later errors\n",
    "     validation_split_name = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedDecisionAvgModel class defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Define the Combined Model\n",
    "\n",
    "class CombinedDecisionAvgModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, num_classes,\n",
    "                 audio_hidden_dim, text_hidden_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        # Pathway for Audio Features\n",
    "        self.audio_classifier = nn.Sequential(\n",
    "            nn.Linear(audio_dim, audio_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(audio_hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "        # Pathway for Text Features\n",
    "        self.text_classifier = nn.Sequential(\n",
    "            nn.Linear(text_dim, text_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(text_hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_embedding, text_embedding):\n",
    "        # Get logits from each pathway\n",
    "        audio_logits = self.audio_classifier(audio_embedding) # (batch_size, num_classes)\n",
    "        text_logits = self.text_classifier(text_embedding)   # (batch_size, num_classes)\n",
    "\n",
    "        # Average the logits\n",
    "        # Ensure inputs are float for division\n",
    "        final_logits = (audio_logits.float() + text_logits.float()) / 2.0\n",
    "\n",
    "        return final_logits\n",
    "\n",
    "print(\"CombinedDecisionAvgModel class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined model instantiated.\n",
      "\n",
      "Combined Model Architecture:\n",
      "CombinedDecisionAvgModel(\n",
      "  (audio_classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (text_classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Calculating class weights for the training set...\n",
      "Class weights calculated and moved to device.\n",
      "Using CrossEntropyLoss with class weights.\n",
      "Optimizer defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 4: Instantiate Model, Define Loss, Optimizer\n",
    "\n",
    "model = None\n",
    "criterion = None\n",
    "optimizer = None\n",
    "class_weights = None\n",
    "\n",
    "if processed_dataset:\n",
    "    # --- Instantiate ONE Combined Model ---\n",
    "    model = CombinedDecisionAvgModel(\n",
    "        audio_dim=audio_embedding_dim,\n",
    "        text_dim=text_embedding_dim,\n",
    "        num_classes=num_classes,\n",
    "        audio_hidden_dim=audio_hidden_dim,\n",
    "        text_hidden_dim=text_hidden_dim,\n",
    "        dropout_rate=dropout_rate\n",
    "    ).to(device)\n",
    "\n",
    "    print(\"Combined model instantiated.\")\n",
    "    print(\"\\nCombined Model Architecture:\")\n",
    "    print(model)\n",
    "\n",
    "    # --- Calculate Class Weights (Optional but Recommended) ---\n",
    "    if 'train' in processed_dataset:\n",
    "        # (Calculation code identical to previous Block 4 - can copy paste)\n",
    "        print(\"\\nCalculating class weights for the training set...\")\n",
    "        label_counts = Counter(processed_dataset['train']['label_id'].numpy())\n",
    "        total_samples = len(processed_dataset['train'])\n",
    "        weights = []\n",
    "        for i in range(num_classes):\n",
    "            count = label_counts.get(i, 0)\n",
    "            if count == 0:\n",
    "                 print(f\"Warning: Class index {i} ('{idx_to_label.get(i)}') not found in training data. Assigning weight 1.0.\")\n",
    "                 weights.append(1.0)\n",
    "            else:\n",
    "                weight = total_samples / (num_classes * count)\n",
    "                weights.append(weight)\n",
    "        class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "        print(\"Class weights calculated and moved to device.\")\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(\"Using CrossEntropyLoss with class weights.\")\n",
    "    else:\n",
    "        print(\"Warning: 'train' split not found. Cannot calculate class weights.\")\n",
    "        print(\"Using standard CrossEntropyLoss.\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Define ONE Optimizer ---\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    print(\"Optimizer defined.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping model instantiation, loss, and optimizer definition because the dataset is not ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'validation' as the validation split.\n",
      "Train DataLoader created with 283 batches.\n",
      "Validation DataLoader created using 'validation' split with 32 batches.\n",
      "Note: Test DataLoader not created ('test' split missing).\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Prepare DataLoaders\n",
    "\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "\n",
    "# validation_split_name should be set in Block 2 based on dataset contents\n",
    "print(f\"Using '{validation_split_name}' as the validation split.\")\n",
    "\n",
    "if processed_dataset and model: # Check if dataset and the single model are ready\n",
    "    if 'train' in processed_dataset:\n",
    "        train_dataset = processed_dataset['train']\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "        print(f\"Train DataLoader created with {len(train_loader)} batches.\")\n",
    "    else:\n",
    "        print(\"Warning: Train DataLoader cannot be created ('train' split missing).\")\n",
    "\n",
    "    if validation_split_name in processed_dataset:\n",
    "        val_dataset = processed_dataset[validation_split_name]\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "        print(f\"Validation DataLoader created using '{validation_split_name}' split with {len(val_loader)} batches.\")\n",
    "    else:\n",
    "        print(f\"Warning: Validation DataLoader cannot be created ('{validation_split_name}' split missing).\")\n",
    "\n",
    "\n",
    "    if 'test' in processed_dataset:\n",
    "        test_dataset = processed_dataset['test']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if device == 'cuda' else False)\n",
    "        print(f\"Test DataLoader created with {len(test_loader)} batches.\")\n",
    "    else:\n",
    "        print(\"Note: Test DataLoader not created ('test' split missing).\")\n",
    "\n",
    "    # Verify required loaders exist for training\n",
    "    if not train_loader or not val_loader:\n",
    "        print(\"\\nERROR: Training cannot proceed without both train and validation DataLoaders.\")\n",
    "        # Invalidate model if loaders are missing\n",
    "        model = None\n",
    "\n",
    "else:\n",
    "    print(\"Skipping DataLoader creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified training and evaluation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Define Unified Training & Evaluation Functions\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    \"\"\"Trains one epoch for the combined model.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        audio_emb = batch['audio_embedding'].to(device)\n",
    "        text_emb = batch['text_embedding'].to(device)\n",
    "        labels = batch['label_id'].to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Get final logits (already averaged inside the model)\n",
    "        final_logits = model(audio_emb, text_emb)\n",
    "        loss = criterion(final_logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(final_logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    return avg_loss, accuracy, f1_macro\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluates the combined model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            audio_emb = batch['audio_embedding'].to(device)\n",
    "            text_emb = batch['text_embedding'].to(device)\n",
    "            labels = batch['label_id'].to(device, dtype=torch.long)\n",
    "\n",
    "            # Get final logits (already averaged inside the model)\n",
    "            final_logits = model(audio_emb, text_emb)\n",
    "            # Calculate loss based on final logits if criterion is provided\n",
    "            if criterion:\n",
    "                 loss = criterion(final_logits, labels)\n",
    "                 total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(final_logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy()) # Use labels from CPU for sklearn metrics\n",
    "            if criterion:\n",
    "                 progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader) if criterion and len(data_loader) > 0 else 0.0\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"\\n--- Combined Model Classification Report ---\")\n",
    "    target_names = [idx_to_label.get(i, f\"Class_{i}\") for i in range(num_classes)]\n",
    "    present_labels = sorted(list(set(all_labels)))\n",
    "    filtered_target_names=[idx_to_label.get(i, f\"Class_{i}\") for i in present_labels]\n",
    "    try:\n",
    "        print(classification_report(all_labels, all_preds, labels=present_labels, target_names=filtered_target_names, zero_division=0))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate classification report: {e}\")\n",
    "\n",
    "    return avg_loss, accuracy, f1_macro, f1_weighted\n",
    "\n",
    "print(\"Unified training and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training Combined Model ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1792692e0f524767bea122afd7c95cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c1357985f647f5a62eae9ae3b29cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.32      0.23      0.27       170\n",
      "       happy       0.50      0.02      0.03        63\n",
      "         sad       0.30      0.78      0.43       129\n",
      "       angry       0.25      0.69      0.37       127\n",
      "  frustrated       0.32      0.18      0.23       285\n",
      "     excited       0.53      0.08      0.14       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.00      0.00      0.00        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30      1004\n",
      "   macro avg       0.25      0.22      0.16      1004\n",
      "weighted avg       0.35      0.30      0.24      1004\n",
      "\n",
      "\n",
      "Epoch 1/15 [Combined]:\n",
      "  Train Loss: 2.2205 | Train Acc: 0.2341 | Train F1 (Macro): 0.1337\n",
      "  Val Loss:   2.1434 | Val Acc:   0.2958 | Val F1 (Macro): 0.1638 | Val F1 (Weighted): 0.2431\n",
      "  New best validation F1 Macro: 0.1638. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5eb2707c154420b21eda7b528a28ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fbef8dbfad48cfbf04d066da37a49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.28      0.12      0.17       170\n",
      "       happy       0.10      0.05      0.06        63\n",
      "         sad       0.34      0.73      0.46       129\n",
      "       angry       0.28      0.66      0.40       127\n",
      "  frustrated       0.36      0.19      0.25       285\n",
      "     excited       0.40      0.30      0.34       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.22      0.39      0.28        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      1004\n",
      "   macro avg       0.22      0.27      0.22      1004\n",
      "weighted avg       0.32      0.32      0.28      1004\n",
      "\n",
      "\n",
      "Epoch 2/15 [Combined]:\n",
      "  Train Loss: 2.1231 | Train Acc: 0.2794 | Train F1 (Macro): 0.1546\n",
      "  Val Loss:   2.0376 | Val Acc:   0.3197 | Val F1 (Macro): 0.2179 | Val F1 (Weighted): 0.2842\n",
      "  New best validation F1 Macro: 0.2179. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fab9ff857e740fdbe03d0ce3581068e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f98fe07d814a0188e35da7fdd03c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.36      0.09      0.15       170\n",
      "       happy       0.00      0.00      0.00        63\n",
      "         sad       0.36      0.71      0.48       129\n",
      "       angry       0.28      0.69      0.39       127\n",
      "  frustrated       0.37      0.23      0.28       285\n",
      "     excited       0.41      0.33      0.36       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.19      0.50      0.27        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33      1004\n",
      "   macro avg       0.22      0.28      0.22      1004\n",
      "weighted avg       0.33      0.33      0.29      1004\n",
      "\n",
      "\n",
      "Epoch 3/15 [Combined]:\n",
      "  Train Loss: 2.0486 | Train Acc: 0.2884 | Train F1 (Macro): 0.1700\n",
      "  Val Loss:   1.9695 | Val Acc:   0.3327 | Val F1 (Macro): 0.2157 | Val F1 (Weighted): 0.2931\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b765054d84a84a4e99a107e8a1e1ca6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351532b7b4a045ad8034143b0afe614f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.34      0.10      0.15       170\n",
      "       happy       0.11      0.05      0.07        63\n",
      "         sad       0.36      0.74      0.49       129\n",
      "       angry       0.27      0.68      0.39       127\n",
      "  frustrated       0.38      0.15      0.22       285\n",
      "     excited       0.37      0.35      0.36       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.19      0.50      0.28        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      1004\n",
      "   macro avg       0.22      0.28      0.22      1004\n",
      "weighted avg       0.33      0.32      0.28      1004\n",
      "\n",
      "\n",
      "Epoch 4/15 [Combined]:\n",
      "  Train Loss: 2.0084 | Train Acc: 0.3065 | Train F1 (Macro): 0.1798\n",
      "  Val Loss:   1.9234 | Val Acc:   0.3197 | Val F1 (Macro): 0.2159 | Val F1 (Weighted): 0.2778\n",
      "  Validation F1 Macro did not improve. (2/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026b20f4fb304c87acf5254c5192e2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1498e38bb4b54c5393be501bae7b6270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.38      0.07      0.12       170\n",
      "       happy       0.15      0.10      0.12        63\n",
      "         sad       0.39      0.71      0.50       129\n",
      "       angry       0.32      0.63      0.42       127\n",
      "  frustrated       0.38      0.21      0.27       285\n",
      "     excited       0.39      0.38      0.38       197\n",
      "        fear       0.03      0.07      0.04        14\n",
      "    surprise       0.18      0.56      0.27        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33      1004\n",
      "   macro avg       0.25      0.30      0.24      1004\n",
      "weighted avg       0.35      0.33      0.30      1004\n",
      "\n",
      "\n",
      "Epoch 5/15 [Combined]:\n",
      "  Train Loss: 1.9813 | Train Acc: 0.3027 | Train F1 (Macro): 0.1864\n",
      "  Val Loss:   1.8836 | Val Acc:   0.3347 | Val F1 (Macro): 0.2366 | Val F1 (Weighted): 0.3037\n",
      "  New best validation F1 Macro: 0.2366. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe81c3af5f241ae96d2eccffc619e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803808220ddf40e588080cda066efb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.46      0.07      0.12       170\n",
      "       happy       0.12      0.19      0.14        63\n",
      "         sad       0.39      0.69      0.50       129\n",
      "       angry       0.28      0.66      0.40       127\n",
      "  frustrated       0.38      0.13      0.20       285\n",
      "     excited       0.39      0.31      0.35       197\n",
      "        fear       0.05      0.07      0.06        14\n",
      "    surprise       0.14      0.56      0.23        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31      1004\n",
      "   macro avg       0.25      0.30      0.22      1004\n",
      "weighted avg       0.36      0.31      0.27      1004\n",
      "\n",
      "\n",
      "Epoch 6/15 [Combined]:\n",
      "  Train Loss: 1.9560 | Train Acc: 0.3167 | Train F1 (Macro): 0.1964\n",
      "  Val Loss:   1.8544 | Val Acc:   0.3068 | Val F1 (Macro): 0.2216 | Val F1 (Weighted): 0.2732\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927c6134eab043b7927f83d9104d0c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7147f4ba32a74b06b7474d6a8aa05305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.44      0.15      0.23       170\n",
      "       happy       0.12      0.13      0.12        63\n",
      "         sad       0.41      0.71      0.52       129\n",
      "       angry       0.32      0.65      0.43       127\n",
      "  frustrated       0.41      0.21      0.28       285\n",
      "     excited       0.41      0.39      0.40       197\n",
      "        fear       0.00      0.00      0.00        14\n",
      "    surprise       0.15      0.56      0.24        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35      1004\n",
      "   macro avg       0.25      0.31      0.25      1004\n",
      "weighted avg       0.38      0.35      0.33      1004\n",
      "\n",
      "\n",
      "Epoch 7/15 [Combined]:\n",
      "  Train Loss: 1.9229 | Train Acc: 0.3214 | Train F1 (Macro): 0.2049\n",
      "  Val Loss:   1.8329 | Val Acc:   0.3516 | Val F1 (Macro): 0.2457 | Val F1 (Weighted): 0.3282\n",
      "  New best validation F1 Macro: 0.2457. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f66a2e0a11482b8347df24e92a79a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69464210ba424e1dad4abe62d9121114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.44      0.14      0.21       170\n",
      "       happy       0.13      0.16      0.14        63\n",
      "         sad       0.40      0.71      0.52       129\n",
      "       angry       0.35      0.65      0.45       127\n",
      "  frustrated       0.44      0.24      0.31       285\n",
      "     excited       0.42      0.35      0.38       197\n",
      "        fear       0.09      0.14      0.11        14\n",
      "    surprise       0.17      0.61      0.27        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36      1004\n",
      "   macro avg       0.27      0.33      0.27      1004\n",
      "weighted avg       0.39      0.36      0.34      1004\n",
      "\n",
      "\n",
      "Epoch 8/15 [Combined]:\n",
      "  Train Loss: 1.9012 | Train Acc: 0.3300 | Train F1 (Macro): 0.2127\n",
      "  Val Loss:   1.8062 | Val Acc:   0.3576 | Val F1 (Macro): 0.2660 | Val F1 (Weighted): 0.3381\n",
      "  New best validation F1 Macro: 0.2660. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a701445e284748b0d96a7930622835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc07dd24b8da4b3d9af9c96833382f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.46      0.17      0.25       170\n",
      "       happy       0.12      0.22      0.16        63\n",
      "         sad       0.39      0.73      0.50       129\n",
      "       angry       0.36      0.63      0.46       127\n",
      "  frustrated       0.45      0.25      0.32       285\n",
      "     excited       0.39      0.25      0.30       197\n",
      "        fear       0.09      0.07      0.08        14\n",
      "    surprise       0.18      0.61      0.28        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35      1004\n",
      "   macro avg       0.27      0.33      0.26      1004\n",
      "weighted avg       0.39      0.35      0.33      1004\n",
      "\n",
      "\n",
      "Epoch 9/15 [Combined]:\n",
      "  Train Loss: 1.8829 | Train Acc: 0.3222 | Train F1 (Macro): 0.2087\n",
      "  Val Loss:   1.7986 | Val Acc:   0.3476 | Val F1 (Macro): 0.2607 | Val F1 (Weighted): 0.3308\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b75d23ebf3b40299b2d06d96e7697ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be88f4b7143477a9190afa6d2562ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.49      0.18      0.27       170\n",
      "       happy       0.13      0.19      0.15        63\n",
      "         sad       0.41      0.71      0.52       129\n",
      "       angry       0.34      0.65      0.44       127\n",
      "  frustrated       0.44      0.20      0.28       285\n",
      "     excited       0.42      0.37      0.39       197\n",
      "        fear       0.15      0.14      0.15        14\n",
      "    surprise       0.19      0.67      0.29        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36      1004\n",
      "   macro avg       0.29      0.35      0.28      1004\n",
      "weighted avg       0.40      0.36      0.34      1004\n",
      "\n",
      "\n",
      "Epoch 10/15 [Combined]:\n",
      "  Train Loss: 1.8695 | Train Acc: 0.3397 | Train F1 (Macro): 0.2235\n",
      "  Val Loss:   1.7797 | Val Acc:   0.3596 | Val F1 (Macro): 0.2769 | Val F1 (Weighted): 0.3401\n",
      "  New best validation F1 Macro: 0.2769. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d18e9451e448588b5a6c070916d673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f00793c07034e36a105766883a5b716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.49      0.20      0.28       170\n",
      "       happy       0.12      0.22      0.16        63\n",
      "         sad       0.41      0.74      0.52       129\n",
      "       angry       0.34      0.65      0.45       127\n",
      "  frustrated       0.46      0.22      0.30       285\n",
      "     excited       0.40      0.26      0.32       197\n",
      "        fear       0.11      0.21      0.15        14\n",
      "    surprise       0.20      0.56      0.30        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35      1004\n",
      "   macro avg       0.28      0.34      0.28      1004\n",
      "weighted avg       0.40      0.35      0.34      1004\n",
      "\n",
      "\n",
      "Epoch 11/15 [Combined]:\n",
      "  Train Loss: 1.8445 | Train Acc: 0.3414 | Train F1 (Macro): 0.2250\n",
      "  Val Loss:   1.7698 | Val Acc:   0.3536 | Val F1 (Macro): 0.2757 | Val F1 (Weighted): 0.3378\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbc02f70807467c9c33304b493241f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659a0f6eee554e038e508ecbcaa5891b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.45      0.24      0.31       170\n",
      "       happy       0.14      0.16      0.15        63\n",
      "         sad       0.41      0.74      0.53       129\n",
      "       angry       0.36      0.65      0.46       127\n",
      "  frustrated       0.45      0.24      0.31       285\n",
      "     excited       0.42      0.34      0.38       197\n",
      "        fear       0.17      0.14      0.15        14\n",
      "    surprise       0.20      0.67      0.30        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.37      1004\n",
      "   macro avg       0.29      0.35      0.29      1004\n",
      "weighted avg       0.40      0.37      0.36      1004\n",
      "\n",
      "\n",
      "Epoch 12/15 [Combined]:\n",
      "  Train Loss: 1.8381 | Train Acc: 0.3409 | Train F1 (Macro): 0.2299\n",
      "  Val Loss:   1.7576 | Val Acc:   0.3745 | Val F1 (Macro): 0.2878 | Val F1 (Weighted): 0.3569\n",
      "  New best validation F1 Macro: 0.2878. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9da3846384e49f89c1c39c9969ac4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbcc16994c249e5ab4aec507c7705cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.44      0.23      0.30       170\n",
      "       happy       0.12      0.17      0.15        63\n",
      "         sad       0.45      0.68      0.54       129\n",
      "       angry       0.36      0.67      0.47       127\n",
      "  frustrated       0.45      0.26      0.33       285\n",
      "     excited       0.43      0.35      0.38       197\n",
      "        fear       0.20      0.14      0.17        14\n",
      "    surprise       0.19      0.67      0.30        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38      1004\n",
      "   macro avg       0.29      0.35      0.29      1004\n",
      "weighted avg       0.40      0.38      0.36      1004\n",
      "\n",
      "\n",
      "Epoch 13/15 [Combined]:\n",
      "  Train Loss: 1.8148 | Train Acc: 0.3534 | Train F1 (Macro): 0.2357\n",
      "  Val Loss:   1.7438 | Val Acc:   0.3765 | Val F1 (Macro): 0.2919 | Val F1 (Weighted): 0.3641\n",
      "  New best validation F1 Macro: 0.2919. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d88c0d5b4cb435a855fecf073ce9961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c49828dcc61441fbfd7d78ca7524b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.45      0.31      0.37       170\n",
      "       happy       0.14      0.22      0.17        63\n",
      "         sad       0.44      0.70      0.54       129\n",
      "       angry       0.37      0.66      0.47       127\n",
      "  frustrated       0.47      0.26      0.33       285\n",
      "     excited       0.42      0.26      0.32       197\n",
      "        fear       0.12      0.14      0.13        14\n",
      "    surprise       0.19      0.67      0.29        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38      1004\n",
      "   macro avg       0.29      0.36      0.29      1004\n",
      "weighted avg       0.41      0.38      0.37      1004\n",
      "\n",
      "\n",
      "Epoch 14/15 [Combined]:\n",
      "  Train Loss: 1.8111 | Train Acc: 0.3613 | Train F1 (Macro): 0.2418\n",
      "  Val Loss:   1.7280 | Val Acc:   0.3775 | Val F1 (Macro): 0.2924 | Val F1 (Weighted): 0.3671\n",
      "  New best validation F1 Macro: 0.2924. Saving model state.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956d965b3d6f4f6c808b9a3bdf7527b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d708e1e50c41401ebdab3fab32c62db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.49      0.23      0.31       170\n",
      "       happy       0.13      0.24      0.17        63\n",
      "         sad       0.40      0.73      0.52       129\n",
      "       angry       0.38      0.65      0.48       127\n",
      "  frustrated       0.53      0.23      0.32       285\n",
      "     excited       0.39      0.29      0.33       197\n",
      "        fear       0.09      0.21      0.12        14\n",
      "    surprise       0.22      0.61      0.33        18\n",
      "       other       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.37      1004\n",
      "   macro avg       0.29      0.36      0.29      1004\n",
      "weighted avg       0.42      0.37      0.35      1004\n",
      "\n",
      "\n",
      "Epoch 15/15 [Combined]:\n",
      "  Train Loss: 1.7945 | Train Acc: 0.3603 | Train F1 (Macro): 0.2375\n",
      "  Val Loss:   1.7254 | Val Acc:   0.3665 | Val F1 (Macro): 0.2871 | Val F1 (Weighted): 0.3546\n",
      "  Validation F1 Macro did not improve. (1/3)\n",
      "--------------------------------------------------\n",
      "\n",
      "Training finished.\n",
      "Loading model state from epoch with best validation F1 Macro: 0.2924\n"
     ]
    }
   ],
   "source": [
    "# Block 7: Training Loop (Train the Combined Model)\n",
    "\n",
    "best_model_state = None\n",
    "best_val_f1_macro = -1.0 # Initialize best validation F1 score\n",
    "epochs_no_improve = 0    # Counter for epochs without improvement\n",
    "early_stopping_patience = 3 # Stop after N epochs with no improvement\n",
    "\n",
    "# --- Check if ready for training ---\n",
    "if model and criterion and optimizer and train_loader and val_loader:\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Training Combined Model \" + \"=\"*20)\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training ---\n",
    "        train_loss, train_acc, train_f1 = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "\n",
    "        # --- Evaluation ---\n",
    "        val_loss, val_acc, val_f1_macro, val_f1_weighted = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs} [Combined]:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1 (Macro): {train_f1:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val F1 (Macro): {val_f1_macro:.4f} | Val F1 (Weighted): {val_f1_weighted:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_f1_macro > best_val_f1_macro:\n",
    "            best_val_f1_macro = val_f1_macro\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            print(f\"  New best validation F1 Macro: {best_val_f1_macro:.4f}. Saving model state.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Validation F1 Macro did not improve. ({epochs_no_improve}/{early_stopping_patience})\")\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "\n",
    "    # --- Load Best Model State ---\n",
    "    if best_model_state:\n",
    "        print(f\"Loading model state from epoch with best validation F1 Macro: {best_val_f1_macro:.4f}\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"Warning: No best model state was saved (perhaps training stopped early or validation metric never improved).\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping training loop: One or more required components (model, criterion, optimizer, loaders) are missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping final test set evaluation: Test DataLoader not available.\n"
     ]
    }
   ],
   "source": [
    "# Block 8: Final Evaluation on Test Set\n",
    "\n",
    "if model and test_loader and best_model_state:\n",
    "    print(\"\\n\" + \"=\"*20 + \" Evaluating Combined Model on Test Set \" + \"=\"*20)\n",
    "\n",
    "    # Ensure the best model state is loaded\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Evaluate using the unified evaluate function (criterion=None if only metrics needed)\n",
    "    test_loss, test_acc, test_f1_macro, test_f1_weighted = evaluate(\n",
    "        model,\n",
    "        test_loader,\n",
    "        criterion, # Pass criterion if you want test loss, else None\n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Final Test Set Performance (Combined Model - Logit Avg):\")\n",
    "    # print(f\"  Test Loss:        {test_loss:.4f}\") # Only if criterion was passed\n",
    "    print(f\"  Test Accuracy:    {test_acc:.4f}\")\n",
    "    print(f\"  Test F1 (Macro):  {test_f1_macro:.4f}\")\n",
    "    print(f\"  Test F1 (Weighted):{test_f1_weighted:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "elif not test_loader:\n",
    "    print(\"\\nSkipping final test set evaluation: Test DataLoader not available.\")\n",
    "elif not best_model_state:\n",
    "     print(\"\\nSkipping final test set evaluation: Best model state not available (training may have failed or not run).\")\n",
    "else:\n",
    "     print(\"\\nSkipping final test set evaluation due to missing components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combined model state dictionary saved to: combined_decision_avg_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Block 9: Save Final Model\n",
    "\n",
    "if model and best_model_state:\n",
    "    try:\n",
    "        torch.save(best_model_state, model_save_path)\n",
    "        print(f\"Best combined model state dictionary saved to: {model_save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving combined model: {e}\")\n",
    "else:\n",
    "    print(\"Skipping model saving: Model not trained or best state not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "535ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
